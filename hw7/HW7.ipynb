{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSGDbExff_I"
      },
      "source": [
        "# **Homework 7 - Bert (Question Answering)**\n",
        "\n",
        "If you have any questions, feel free to email us at mlta-2022-spring@googlegroups.com\n",
        "\n",
        "\n",
        "\n",
        "Slide:    [Link](https://docs.google.com/presentation/d/1H5ZONrb2LMOCixLY7D5_5-7LkIaXO6AGEaV2mRdTOMY/edit?usp=sharing)　Kaggle: [Link](https://www.kaggle.com/c/ml2022spring-hw7)　Data: [Link](https://drive.google.com/uc?id=1AVgZvy3VFeg0fX-6WQJMHPVrx3A-M1kb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGOr_eS3wJJf"
      },
      "source": [
        "## Task description\n",
        "- Chinese Extractive Question Answering\n",
        "  - Input: Paragraph + Question\n",
        "  - Output: Answer\n",
        "\n",
        "- Objective: Learn how to fine tune a pretrained model on downstream task using transformers\n",
        "\n",
        "- Todo\n",
        "    - Fine tune a pretrained chinese BERT model\n",
        "    - Change hyperparameters (e.g. doc_stride)\n",
        "    - Apply linear learning rate decay\n",
        "    - Try other pretrained models\n",
        "    - Improve preprocessing\n",
        "    - Improve postprocessing\n",
        "- Training tips\n",
        "    - Automatic mixed precision\n",
        "    - Gradient accumulation\n",
        "    - Ensemble\n",
        "\n",
        "- Estimated training time (tesla t4 with automatic mixed precision enabled)\n",
        "    - Simple: 8mins\n",
        "    - Medium: 8mins\n",
        "    - Strong: 25mins\n",
        "    - Boss: 2.5hrs\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ1fSAJE2oaC"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YPrc4Eie9Yo5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Apr 21 17:14:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  On   | 00000000:65:00.0  On |                  N/A |\n",
            "|  0%   34C    P8    13W / 275W |    178MiB / 11177MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1170      G   /usr/lib/xorg/Xorg                109MiB |\n",
            "|    0   N/A  N/A      1750      G   /usr/bin/gnome-shell               38MiB |\n",
            "|    0   N/A  N/A      1766      G   ...mviewer/tv_bin/TeamViewer        3MiB |\n",
            "|    0   N/A  N/A    709148      G   ...RendererForSitePerProcess       21MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# # Download link 1\n",
        "# !gdown --id '1AVgZvy3VFeg0fX-6WQJMHPVrx3A-M1kb' --output hw7_data.zip\n",
        "\n",
        "# # Download Link 2 (if the above link fails) \n",
        "# # !gdown --id '1qwjbRjq481lHsnTrrF4OjKQnxzgoLEFR' --output hw7_data.zip\n",
        "\n",
        "# # Download Link 3 (if the above link fails) \n",
        "# # !gdown --id '1QXuWjNRZH6DscSd6QcRER0cnxmpZvijn' --output hw7_data.zip\n",
        "\n",
        "# !unzip -o hw7_data.zip\n",
        "\n",
        "# For this HW, K80 < P4 < T4 < P100 <= T4(fp16) < V100\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TevOvhC03m0h"
      },
      "source": [
        "## Install transformers\n",
        "\n",
        "Documentation for the toolkit:　https://huggingface.co/transformers/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tbxWFX_jpDom"
      },
      "outputs": [],
      "source": [
        "# You are allowed to change version of transformers or use other toolkits\n",
        "# !pip install transformers==4.5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dKM4yCh4LI_"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WOTHHtWJoahe"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset \n",
        "from transformers import AdamW, BertForQuestionAnswering, BertTokenizerFast\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import transformers\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Fix random seed for reproducibility\n",
        "def same_seeds(seed):\n",
        "\t  torch.manual_seed(seed)\n",
        "\t  if torch.cuda.is_available():\n",
        "\t\t    torch.cuda.manual_seed(seed)\n",
        "\t\t    torch.cuda.manual_seed_all(seed)\n",
        "\t  np.random.seed(seed)\n",
        "\t  random.seed(seed)\n",
        "\t  torch.backends.cudnn.benchmark = False\n",
        "\t  torch.backends.cudnn.deterministic = True\n",
        "same_seeds(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7pBtSZP1SKQO"
      },
      "outputs": [],
      "source": [
        "# Change \"fp16_training\" to True to support automatic mixed precision training (fp16)\t\n",
        "fp16_training = False\n",
        "\n",
        "if fp16_training:\n",
        "    !pip install accelerate==0.2.0\n",
        "    from accelerate import Accelerator\n",
        "    accelerator = Accelerator(fp16=True)\n",
        "    device = accelerator.device\n",
        "\n",
        "# Documentation for the toolkit:  https://huggingface.co/docs/accelerate/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YgXHuVLp_6j"
      },
      "source": [
        "## Load Model and Tokenizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xyBCYGjAp3ym"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/haoyu/.local/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = BertForQuestionAnswering.from_pretrained(\"uer/roberta-base-chinese-extractive-qa\").to(device)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"uer/roberta-base-chinese-extractive-qa\")\n",
        "\n",
        "# model = BertForQuestionAnswering.from_pretrained(\"hfl/chinese-macbert-large\").to(device)\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(\"hfl/chinese-macbert-large\")\n",
        "\n",
        "# You can safely ignore the warning message (it pops up because new prediction heads for QA are initialized randomly)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Td-GTmk5OW4"
      },
      "source": [
        "## Read Data\n",
        "\n",
        "- Training set: 31690 QA pairs\n",
        "- Dev set: 4131  QA pairs\n",
        "- Test set: 4957  QA pairs\n",
        "\n",
        "- {train/dev/test}_questions:\t\n",
        "  - List of dicts with the following keys:\n",
        "   - id (int)\n",
        "   - paragraph_id (int)\n",
        "   - question_text (string)\n",
        "   - answer_text (string)\n",
        "   - answer_start (int)\n",
        "   - answer_end (int)\n",
        "- {train/dev/test}_paragraphs: \n",
        "  - List of strings\n",
        "  - paragraph_ids in questions correspond to indexs in paragraphs\n",
        "  - A paragraph may be used by several questions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NvX7hlepogvu"
      },
      "outputs": [],
      "source": [
        "def read_data(file):\n",
        "    with open(file, 'r', encoding=\"utf-8\") as reader:\n",
        "        data = json.load(reader)\n",
        "    return data[\"questions\"], data[\"paragraphs\"]\n",
        "\n",
        "train_questions, train_paragraphs = read_data(\"hw7_train.json\")\n",
        "dev_questions, dev_paragraphs = read_data(\"hw7_dev.json\")\n",
        "test_questions, test_paragraphs = read_data(\"hw7_test.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm0rpTHq0e4N"
      },
      "source": [
        "## Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rTZ6B70Hoxie"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "# Tokenize questions and paragraphs separately\n",
        "# 「add_special_tokens」 is set to False since special tokens will be added when tokenized questions and paragraphs are combined in datset __getitem__ \n",
        "\n",
        "train_questions_tokenized = tokenizer([train_question[\"question_text\"] for train_question in train_questions], add_special_tokens=False)\n",
        "dev_questions_tokenized = tokenizer([dev_question[\"question_text\"] for dev_question in dev_questions], add_special_tokens=False)\n",
        "test_questions_tokenized = tokenizer([test_question[\"question_text\"] for test_question in test_questions], add_special_tokens=False) \n",
        "\n",
        "train_paragraphs_tokenized = tokenizer(train_paragraphs, add_special_tokens=False)\n",
        "dev_paragraphs_tokenized = tokenizer(dev_paragraphs, add_special_tokens=False)\n",
        "test_paragraphs_tokenized = tokenizer(test_paragraphs, add_special_tokens=False)\n",
        "\n",
        "# You can safely ignore the warning message as tokenized sequences will be futher processed in datset __getitem__ before passing to model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws8c8_4d5UCI"
      },
      "source": [
        "## Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xjooag-Swnuh"
      },
      "outputs": [],
      "source": [
        "class QA_Dataset(Dataset):\n",
        "    def __init__(self, split, questions, tokenized_questions, tokenized_paragraphs):\n",
        "        self.split = split\n",
        "        self.questions = questions\n",
        "        self.tokenized_questions = tokenized_questions\n",
        "        self.tokenized_paragraphs = tokenized_paragraphs\n",
        "        self.max_question_len = 40\n",
        "        self.max_paragraph_len = 200\n",
        "        # self.max_paragraph_len = 150\n",
        "\n",
        "        \n",
        "        ##### TODO: Change value of doc_stride #####\n",
        "        self.doc_stride = 50\n",
        "        # self.doc_stride = 150\n",
        "\n",
        "        # Input sequence length = [CLS] + question + [SEP] + paragraph + [SEP]\n",
        "        self.max_seq_len = 1 + self.max_question_len + 1 + self.max_paragraph_len + 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question = self.questions[idx]\n",
        "        tokenized_question = self.tokenized_questions[idx]\n",
        "        tokenized_paragraph = self.tokenized_paragraphs[question[\"paragraph_id\"]]\n",
        "\n",
        "        ##### TODO: Preprocessing #####\n",
        "        # Hint: How to prevent model from learning something it should not learn\n",
        "\n",
        "        if self.split == \"train\":\n",
        "            # Convert answer's start/end positions in paragraph_text to start/end positions in tokenized_paragraph  \n",
        "            answer_start_token = tokenized_paragraph.char_to_token(question[\"answer_start\"])\n",
        "            answer_end_token = tokenized_paragraph.char_to_token(question[\"answer_end\"])\n",
        "\n",
        "            # A single window is obtained by slicing the portion of paragraph containing the answer\n",
        "            mid = int((answer_start_token + answer_end_token) // (2+random.uniform(-1, 1)))\n",
        "            paragraph_start = max(0, min(mid - self.max_paragraph_len // 2, len(tokenized_paragraph) - self.max_paragraph_len))\n",
        "            paragraph_end = paragraph_start + self.max_paragraph_len\n",
        "            \n",
        "            # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n",
        "            input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102] \n",
        "            input_ids_paragraph = tokenized_paragraph.ids[paragraph_start : paragraph_end] + [102]\t\t\n",
        "            \n",
        "            # Convert answer's start/end positions in tokenized_paragraph to start/end positions in the window  \n",
        "            answer_start_token += len(input_ids_question) - paragraph_start\n",
        "            answer_end_token += len(input_ids_question) - paragraph_start\n",
        "            \n",
        "            # Pad sequence and obtain inputs to model \n",
        "            input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n",
        "            return torch.tensor(input_ids), torch.tensor(token_type_ids), torch.tensor(attention_mask), answer_start_token, answer_end_token\n",
        "\n",
        "        # Validation/Testing\n",
        "        else:\n",
        "            input_ids_list, token_type_ids_list, attention_mask_list = [], [], []\n",
        "            \n",
        "            # Paragraph is split into several windows, each with start positions separated by step \"doc_stride\"\n",
        "            for i in range(0, len(tokenized_paragraph), self.doc_stride):\n",
        "                \n",
        "                # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n",
        "                input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102]\n",
        "                input_ids_paragraph = tokenized_paragraph.ids[i : i + self.max_paragraph_len] + [102]\n",
        "                \n",
        "                # Pad sequence and obtain inputs to model\n",
        "                input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n",
        "                \n",
        "                input_ids_list.append(input_ids)\n",
        "                token_type_ids_list.append(token_type_ids)\n",
        "                attention_mask_list.append(attention_mask)\n",
        "            \n",
        "            return torch.tensor(input_ids_list), torch.tensor(token_type_ids_list), torch.tensor(attention_mask_list)\n",
        "\n",
        "    def padding(self, input_ids_question, input_ids_paragraph):\n",
        "        # Pad zeros if sequence length is shorter than max_seq_len\n",
        "        padding_len = self.max_seq_len - len(input_ids_question) - len(input_ids_paragraph)\n",
        "        # Indices of input sequence tokens in the vocabulary\n",
        "        input_ids = input_ids_question + input_ids_paragraph + [0] * padding_len\n",
        "        # Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]\n",
        "        token_type_ids = [0] * len(input_ids_question) + [1] * len(input_ids_paragraph) + [0] * padding_len\n",
        "        # Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]\n",
        "        attention_mask = [1] * (len(input_ids_question) + len(input_ids_paragraph)) + [0] * padding_len\n",
        "        \n",
        "        return input_ids, token_type_ids, attention_mask\n",
        "\n",
        "train_set = QA_Dataset(\"train\", train_questions, train_questions_tokenized, train_paragraphs_tokenized)\n",
        "dev_set = QA_Dataset(\"dev\", dev_questions, dev_questions_tokenized, dev_paragraphs_tokenized)\n",
        "test_set = QA_Dataset(\"test\", test_questions, test_questions_tokenized, test_paragraphs_tokenized)\n",
        "\n",
        "train_batch_size = 8\n",
        "\n",
        "# Note: Do NOT change batch size of dev_loader / test_loader !\n",
        "# Although batch size=1, it is actually a batch consisting of several windows from the same QA pair\n",
        "train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True, pin_memory=True)\n",
        "dev_loader = DataLoader(dev_set, batch_size=1, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_H1kqhR8CdM"
      },
      "source": [
        "## Function for Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def index_tokenize(tokens, start, end):\n",
        "    char_count, new_start, new_end = 0, 512, 512\n",
        "    start_flag = False  \n",
        "    print(\"start:\", start)\n",
        "    print(\"end:\", end)\n",
        "    for i, token in enumerate(tokens):\n",
        "        print(\"i:\",i, \" token:\", token)\n",
        "        if token == '[UNK]' or token == '[CLS]' or token == '[SEP]':\n",
        "            if i == start:\n",
        "                new_start = char_count\n",
        "                print(\"new_start1:\", new_start)\n",
        "\n",
        "            if i == end:\n",
        "                new_end = char_count\n",
        "                return new_start, new_end\n",
        "                \n",
        "            char_count += 1\n",
        "            # print(\"char_count1:\",char_count)\n",
        "        else:\n",
        "            for ch in token:\n",
        "                if i == start and start_flag == False:\n",
        "                    new_start = char_count\n",
        "                    start_flag = True\n",
        "                    print(\"new_start2:\", new_start)\n",
        "\n",
        "                if i == end:\n",
        "                    new_end = char_count\n",
        "                    return new_start, new_end\n",
        "\n",
        "                if ch != '#':\n",
        "                    char_count += 1\n",
        "                # print(\"char_count2:\",char_count)\n",
        "\n",
        "           \n",
        "    return start, end           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SqeA3PLPxOHu"
      },
      "outputs": [],
      "source": [
        "def evaluate(data, output, doc_stride=150, paragraph=None, paragraph_tokenized=None):\n",
        "    ##### TODO: Postprocessing #####\n",
        "    # There is a bug and room for improvement in postprocessing \n",
        "    # Hint: Open your prediction file to see what is wrong \n",
        "    \n",
        "    answer = ''\n",
        "    max_prob = float('-inf')\n",
        "    num_of_windows = data[0].shape[1]\n",
        "    entire_start_index = 0\n",
        "    entire_end_index = 0\n",
        "\n",
        "    # print(data)\n",
        "    for k in range(num_of_windows):\n",
        "        # print('window', k)\n",
        "        # Obtain answer by choosing the most probable start position / end position\n",
        "        mask = data[1][0][k].bool() & data[2][0][k].bool() # get document, token_type_ids & attention_mask\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        masked_output_start = torch.masked_select(output.start_logits[k], mask)[:-1] # last one is [SEP]\n",
        "        start_prob, start_index = torch.max(masked_output_start, dim=0)\n",
        "\n",
        "        masked_output_start = torch.masked_select(output.end_logits[k], mask)[:-1] # last one is [SEP]\n",
        "        end_prob, end_index = torch.max(masked_output_start, dim=0)\n",
        "        \n",
        "        # Probability of answer is calculated as sum of start_prob and end_prob\n",
        "        prob = start_prob + end_prob\n",
        "        masked_data = torch.masked_select(data[0][0][k].to(device), mask)[:-1]\n",
        "        \n",
        "        # Replace answer if calculated probability is larger than previous windows\n",
        "        if (prob > max_prob) and (end_index - start_index <= 20) and (end_index > start_index):\n",
        "            max_prob = prob\n",
        "            entire_start_index = start_index.item() + doc_stride * k\n",
        "            entire_end_index = end_index.item() + doc_stride * k\n",
        "            # print(\"entire_start_index\", entire_start_index)\n",
        "            # print(\"entire_end_index\", entire_end_index)\n",
        "            # Convert tokens to chars (e.g. [1920, 7032] --> \"大 金\")\n",
        "            answer = tokenizer.decode(masked_data[start_index : end_index + 1])\n",
        "    # 若 [UNK] 在 prediction，使用原始的 paragraph\n",
        "    if '[UNK]' in answer:\n",
        "        print('found [UNK] in prediction.')\n",
        "        print('original pred:', answer)\n",
        "\n",
        "        new_start, new_end = index_tokenize(tokens=paragraph_tokenized, start=entire_start_index, end=entire_end_index)\n",
        "        print(\"new_start\",new_start)\n",
        "        print(\"new_end\", new_end)\n",
        "\n",
        "        answer = paragraph[new_start:new_end+1]\n",
        "        print('final prediction',answer)\n",
        "\n",
        "    # Remove spaces in answer (e.g. \"大 金\" --> \"大金\")\n",
        "    return answer.replace(' ','')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzHQit6eMnKG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3Q-B6ka7xoCM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Training ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5641f36e31bc4bec8ddd4349f7833596",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "  0%|          | 0/3962 [00:00<?, ?it/s]"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Step 100 | loss = 1.489, acc = 0.502\n",
            "Epoch 1 | Step 200 | loss = 1.161, acc = 0.580\n",
            "Epoch 1 | Step 300 | loss = 1.168, acc = 0.587\n",
            "Epoch 1 | Step 400 | loss = 1.098, acc = 0.606\n",
            "Epoch 1 | Step 500 | loss = 1.084, acc = 0.618\n",
            "Epoch 1 | Step 600 | loss = 1.079, acc = 0.625\n",
            "Epoch 1 | Step 700 | loss = 1.026, acc = 0.631\n",
            "Epoch 1 | Step 800 | loss = 1.205, acc = 0.602\n",
            "Epoch 1 | Step 900 | loss = 1.023, acc = 0.630\n",
            "Epoch 1 | Step 1000 | loss = 0.953, acc = 0.655\n",
            "Epoch 1 | Step 1100 | loss = 0.981, acc = 0.642\n",
            "Epoch 1 | Step 1200 | loss = 0.985, acc = 0.652\n",
            "Epoch 1 | Step 1300 | loss = 1.010, acc = 0.611\n",
            "Epoch 1 | Step 1400 | loss = 0.910, acc = 0.665\n",
            "Epoch 1 | Step 1500 | loss = 0.924, acc = 0.661\n",
            "Epoch 1 | Step 1600 | loss = 1.004, acc = 0.661\n",
            "Epoch 1 | Step 1700 | loss = 0.926, acc = 0.671\n",
            "Epoch 1 | Step 1800 | loss = 0.971, acc = 0.650\n",
            "Epoch 1 | Step 1900 | loss = 0.892, acc = 0.674\n",
            "Epoch 1 | Step 2000 | loss = 0.904, acc = 0.664\n",
            "Epoch 1 | Step 2100 | loss = 0.899, acc = 0.666\n",
            "Epoch 1 | Step 2200 | loss = 0.803, acc = 0.695\n",
            "Epoch 1 | Step 2300 | loss = 0.908, acc = 0.676\n",
            "Epoch 1 | Step 2400 | loss = 0.922, acc = 0.670\n",
            "Epoch 1 | Step 2500 | loss = 0.805, acc = 0.701\n",
            "Epoch 1 | Step 2600 | loss = 0.992, acc = 0.675\n",
            "Epoch 1 | Step 2700 | loss = 0.795, acc = 0.694\n",
            "Epoch 1 | Step 2800 | loss = 0.785, acc = 0.711\n",
            "Epoch 1 | Step 2900 | loss = 0.866, acc = 0.684\n",
            "Epoch 1 | Step 3000 | loss = 0.761, acc = 0.702\n",
            "Epoch 1 | Step 3100 | loss = 0.821, acc = 0.688\n",
            "Epoch 1 | Step 3200 | loss = 0.921, acc = 0.697\n",
            "Epoch 1 | Step 3300 | loss = 0.951, acc = 0.681\n",
            "Epoch 1 | Step 3400 | loss = 0.866, acc = 0.691\n",
            "Epoch 1 | Step 3500 | loss = 0.835, acc = 0.706\n",
            "Epoch 1 | Step 3600 | loss = 0.843, acc = 0.692\n",
            "Epoch 1 | Step 3700 | loss = 0.927, acc = 0.683\n",
            "Epoch 1 | Step 3800 | loss = 0.960, acc = 0.656\n",
            "Epoch 1 | Step 3900 | loss = 0.821, acc = 0.701\n",
            "Evaluating Dev Set ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6e3aeef4ea24959a61d6811d9c4cbf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "  0%|          | 0/4131 [00:00<?, ?it/s]"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "found [UNK] in prediction.\n",
            "original pred: 李 [UNK]\n",
            "start: 236\n",
            "end: 237\n",
            "i: 0  token: 《\n",
            "char_count2: 1\n",
            "i: 1  token: 農\n",
            "char_count2: 2\n",
            "i: 2  token: 書\n",
            "char_count2: 3\n",
            "i: 3  token: 》\n",
            "char_count2: 4\n",
            "i: 4  token: 為\n",
            "char_count2: 5\n",
            "i: 5  token: 著\n",
            "char_count2: 6\n",
            "i: 6  token: 名\n",
            "char_count2: 7\n",
            "i: 7  token: 農\n",
            "char_count2: 8\n",
            "i: 8  token: 學\n",
            "char_count2: 9\n",
            "i: 9  token: 家\n",
            "char_count2: 10\n",
            "i: 10  token: 王\n",
            "char_count2: 11\n",
            "i: 11  token: 禎\n",
            "char_count2: 12\n",
            "i: 12  token: 所\n",
            "char_count2: 13\n",
            "i: 13  token: 著\n",
            "char_count2: 14\n",
            "i: 14  token: ，\n",
            "char_count2: 15\n",
            "i: 15  token: ，\n",
            "char_count2: 16\n",
            "i: 16  token: 全\n",
            "char_count2: 17\n",
            "i: 17  token: 書\n",
            "char_count2: 18\n",
            "i: 18  token: 分\n",
            "char_count2: 19\n",
            "i: 19  token: 「\n",
            "char_count2: 20\n",
            "i: 20  token: 農\n",
            "char_count2: 21\n",
            "i: 21  token: 桑\n",
            "char_count2: 22\n",
            "i: 22  token: 通\n",
            "char_count2: 23\n",
            "i: 23  token: 訣\n",
            "char_count2: 24\n",
            "i: 24  token: 」\n",
            "char_count2: 25\n",
            "i: 25  token: 、\n",
            "char_count2: 26\n",
            "i: 26  token: 「\n",
            "char_count2: 27\n",
            "i: 27  token: 百\n",
            "char_count2: 28\n",
            "i: 28  token: 穀\n",
            "char_count2: 29\n",
            "i: 29  token: 譜\n",
            "char_count2: 30\n",
            "i: 30  token: 」\n",
            "char_count2: 31\n",
            "i: 31  token: 、\n",
            "char_count2: 32\n",
            "i: 32  token: 「\n",
            "char_count2: 33\n",
            "i: 33  token: 農\n",
            "char_count2: 34\n",
            "i: 34  token: 器\n",
            "char_count2: 35\n",
            "i: 35  token: 圖\n",
            "char_count2: 36\n",
            "i: 36  token: 譜\n",
            "char_count2: 37\n",
            "i: 37  token: 」\n",
            "char_count2: 38\n",
            "i: 38  token: 三\n",
            "char_count2: 39\n",
            "i: 39  token: 大\n",
            "char_count2: 40\n",
            "i: 40  token: 部\n",
            "char_count2: 41\n",
            "i: 41  token: 分\n",
            "char_count2: 42\n",
            "i: 42  token: ，\n",
            "char_count2: 43\n",
            "i: 43  token: 總\n",
            "char_count2: 44\n",
            "i: 44  token: 結\n",
            "char_count2: 45\n",
            "i: 45  token: 了\n",
            "char_count2: 46\n",
            "i: 46  token: 古\n",
            "char_count2: 47\n",
            "i: 47  token: 代\n",
            "char_count2: 48\n",
            "i: 48  token: 的\n",
            "char_count2: 49\n",
            "i: 49  token: 農\n",
            "char_count2: 50\n",
            "i: 50  token: 業\n",
            "char_count2: 51\n",
            "i: 51  token: 生\n",
            "char_count2: 52\n",
            "i: 52  token: 產\n",
            "char_count2: 53\n",
            "i: 53  token: 經\n",
            "char_count2: 54\n",
            "i: 54  token: 驗\n",
            "char_count2: 55\n",
            "i: 55  token: ，\n",
            "char_count2: 56\n",
            "i: 56  token: 又\n",
            "char_count2: 57\n",
            "i: 57  token: 介\n",
            "char_count2: 58\n",
            "i: 58  token: 紹\n",
            "char_count2: 59\n",
            "i: 59  token: 了\n",
            "char_count2: 60\n",
            "i: 60  token: 當\n",
            "char_count2: 61\n",
            "i: 61  token: 時\n",
            "char_count2: 62\n",
            "i: 62  token: 的\n",
            "char_count2: 63\n",
            "i: 63  token: 新\n",
            "char_count2: 64\n",
            "i: 64  token: 技\n",
            "char_count2: 65\n",
            "i: 65  token: 術\n",
            "char_count2: 66\n",
            "i: 66  token: ，\n",
            "char_count2: 67\n",
            "i: 67  token: 是\n",
            "char_count2: 68\n",
            "i: 68  token: 繼\n",
            "char_count2: 69\n",
            "i: 69  token: 北\n",
            "char_count2: 70\n",
            "i: 70  token: 魏\n",
            "char_count2: 71\n",
            "i: 71  token: 賈\n",
            "char_count2: 72\n",
            "i: 72  token: 思\n",
            "char_count2: 73\n",
            "i: 73  token: 的\n",
            "char_count2: 74\n",
            "i: 74  token: 《\n",
            "char_count2: 75\n",
            "i: 75  token: 齊\n",
            "char_count2: 76\n",
            "i: 76  token: 民\n",
            "char_count2: 77\n",
            "i: 77  token: 要\n",
            "char_count2: 78\n",
            "i: 78  token: 術\n",
            "char_count2: 79\n",
            "i: 79  token: 》\n",
            "char_count2: 80\n",
            "i: 80  token: 之\n",
            "char_count2: 81\n",
            "i: 81  token: 後\n",
            "char_count2: 82\n",
            "i: 82  token: 又\n",
            "char_count2: 83\n",
            "i: 83  token: 一\n",
            "char_count2: 84\n",
            "i: 84  token: 部\n",
            "char_count2: 85\n",
            "i: 85  token: 重\n",
            "char_count2: 86\n",
            "i: 86  token: 要\n",
            "char_count2: 87\n",
            "i: 87  token: 的\n",
            "char_count2: 88\n",
            "i: 88  token: 農\n",
            "char_count2: 89\n",
            "i: 89  token: 業\n",
            "char_count2: 90\n",
            "i: 90  token: 科\n",
            "char_count2: 91\n",
            "i: 91  token: 學\n",
            "char_count2: 92\n",
            "i: 92  token: 著\n",
            "char_count2: 93\n",
            "i: 93  token: 作\n",
            "char_count2: 94\n",
            "i: 94  token: 。\n",
            "char_count2: 95\n",
            "i: 95  token: 王\n",
            "char_count2: 96\n",
            "i: 96  token: 禎\n",
            "char_count2: 97\n",
            "i: 97  token: 認\n",
            "char_count2: 98\n",
            "i: 98  token: 為\n",
            "char_count2: 99\n",
            "i: 99  token: 要\n",
            "char_count2: 100\n",
            "i: 100  token: 不\n",
            "char_count2: 101\n",
            "i: 101  token: 違\n",
            "char_count2: 102\n",
            "i: 102  token: 農\n",
            "char_count2: 103\n",
            "i: 103  token: 時\n",
            "char_count2: 104\n",
            "i: 104  token: 、\n",
            "char_count2: 105\n",
            "i: 105  token: 適\n",
            "char_count2: 106\n",
            "i: 106  token: 時\n",
            "char_count2: 107\n",
            "i: 107  token: 播\n",
            "char_count2: 108\n",
            "i: 108  token: 種\n",
            "char_count2: 109\n",
            "i: 109  token: 、\n",
            "char_count2: 110\n",
            "i: 110  token: 因\n",
            "char_count2: 111\n",
            "i: 111  token: 地\n",
            "char_count2: 112\n",
            "i: 112  token: 制\n",
            "char_count2: 113\n",
            "i: 113  token: 宜\n",
            "char_count2: 114\n",
            "i: 114  token: 、\n",
            "char_count2: 115\n",
            "i: 115  token: 及\n",
            "char_count2: 116\n",
            "i: 116  token: 時\n",
            "char_count2: 117\n",
            "i: 117  token: 施\n",
            "char_count2: 118\n",
            "i: 118  token: 肥\n",
            "char_count2: 119\n",
            "i: 119  token: 、\n",
            "char_count2: 120\n",
            "i: 120  token: 興\n",
            "char_count2: 121\n",
            "i: 121  token: 修\n",
            "char_count2: 122\n",
            "i: 122  token: 水\n",
            "char_count2: 123\n",
            "i: 123  token: 利\n",
            "char_count2: 124\n",
            "i: 124  token: 才\n",
            "char_count2: 125\n",
            "i: 125  token: 是\n",
            "char_count2: 126\n",
            "i: 126  token: 取\n",
            "char_count2: 127\n",
            "i: 127  token: 得\n",
            "char_count2: 128\n",
            "i: 128  token: 農\n",
            "char_count2: 129\n",
            "i: 129  token: 業\n",
            "char_count2: 130\n",
            "i: 130  token: 豐\n",
            "char_count2: 131\n",
            "i: 131  token: 收\n",
            "char_count2: 132\n",
            "i: 132  token: 的\n",
            "char_count2: 133\n",
            "i: 133  token: 保\n",
            "char_count2: 134\n",
            "i: 134  token: 證\n",
            "char_count2: 135\n",
            "i: 135  token: ，\n",
            "char_count2: 136\n",
            "i: 136  token: 其\n",
            "char_count2: 137\n",
            "i: 137  token: 中\n",
            "char_count2: 138\n",
            "i: 138  token: 關\n",
            "char_count2: 139\n",
            "i: 139  token: 於\n",
            "char_count2: 140\n",
            "i: 140  token: 棉\n",
            "char_count2: 141\n",
            "i: 141  token: 桑\n",
            "char_count2: 142\n",
            "i: 142  token: 種\n",
            "char_count2: 143\n",
            "i: 143  token: 植\n",
            "char_count2: 144\n",
            "i: 144  token: 具\n",
            "char_count2: 145\n",
            "i: 145  token: 有\n",
            "char_count2: 146\n",
            "i: 146  token: 現\n",
            "char_count2: 147\n",
            "i: 147  token: 實\n",
            "char_count2: 148\n",
            "i: 148  token: 意\n",
            "char_count2: 149\n",
            "i: 149  token: 義\n",
            "char_count2: 150\n",
            "i: 150  token: 。\n",
            "char_count2: 151\n",
            "i: 151  token: 《\n",
            "char_count2: 152\n",
            "i: 152  token: 農\n",
            "char_count2: 153\n",
            "i: 153  token: 桑\n",
            "char_count2: 154\n",
            "i: 154  token: 衣\n",
            "char_count2: 155\n",
            "i: 155  token: 食\n",
            "char_count2: 156\n",
            "i: 156  token: 撮\n",
            "char_count2: 157\n",
            "i: 157  token: 要\n",
            "char_count2: 158\n",
            "i: 158  token: 》\n",
            "char_count2: 159\n",
            "i: 159  token: 為\n",
            "char_count2: 160\n",
            "i: 160  token: 魯\n",
            "char_count2: 161\n",
            "i: 161  token: 明\n",
            "char_count2: 162\n",
            "i: 162  token: 善\n",
            "char_count2: 163\n",
            "i: 163  token: 所\n",
            "char_count2: 164\n",
            "i: 164  token: 著\n",
            "char_count2: 165\n",
            "i: 165  token: ，\n",
            "char_count2: 166\n",
            "i: 166  token: 此\n",
            "char_count2: 167\n",
            "i: 167  token: 書\n",
            "char_count2: 168\n",
            "i: 168  token: 重\n",
            "char_count2: 169\n",
            "i: 169  token: 在\n",
            "char_count2: 170\n",
            "i: 170  token: 實\n",
            "char_count2: 171\n",
            "i: 171  token: 用\n",
            "char_count2: 172\n",
            "i: 172  token: ，\n",
            "char_count2: 173\n",
            "i: 173  token: 按\n",
            "char_count2: 174\n",
            "i: 174  token: 月\n",
            "char_count2: 175\n",
            "i: 175  token: 記\n",
            "char_count2: 176\n",
            "i: 176  token: 載\n",
            "char_count2: 177\n",
            "i: 177  token: 農\n",
            "char_count2: 178\n",
            "i: 178  token: 事\n",
            "char_count2: 179\n",
            "i: 179  token: 活\n",
            "char_count2: 180\n",
            "i: 180  token: 動\n",
            "char_count2: 181\n",
            "i: 181  token: ，\n",
            "char_count2: 182\n",
            "i: 182  token: 特\n",
            "char_count2: 183\n",
            "i: 183  token: 別\n",
            "char_count2: 184\n",
            "i: 184  token: 還\n",
            "char_count2: 185\n",
            "i: 185  token: 涉\n",
            "char_count2: 186\n",
            "i: 186  token: 及\n",
            "char_count2: 187\n",
            "i: 187  token: 到\n",
            "char_count2: 188\n",
            "i: 188  token: 遊\n",
            "char_count2: 189\n",
            "i: 189  token: 牧\n",
            "char_count2: 190\n",
            "i: 190  token: 生\n",
            "char_count2: 191\n",
            "i: 191  token: 產\n",
            "char_count2: 192\n",
            "i: 192  token: ，\n",
            "char_count2: 193\n",
            "i: 193  token: 可\n",
            "char_count2: 194\n",
            "i: 194  token: 補\n",
            "char_count2: 195\n",
            "i: 195  token: 《\n",
            "char_count2: 196\n",
            "i: 196  token: 農\n",
            "char_count2: 197\n",
            "i: 197  token: 桑\n",
            "char_count2: 198\n",
            "i: 198  token: 輯\n",
            "char_count2: 199\n",
            "i: 199  token: 要\n",
            "char_count2: 200\n",
            "i: 200  token: 》\n",
            "char_count2: 201\n",
            "i: 201  token: 及\n",
            "char_count2: 202\n",
            "i: 202  token: 其\n",
            "char_count2: 203\n",
            "i: 203  token: 它\n",
            "char_count2: 204\n",
            "i: 204  token: 古\n",
            "char_count2: 205\n",
            "i: 205  token: 農\n",
            "char_count2: 206\n",
            "i: 206  token: 書\n",
            "char_count2: 207\n",
            "i: 207  token: 之\n",
            "char_count2: 208\n",
            "i: 208  token: 不\n",
            "char_count2: 209\n",
            "i: 209  token: 足\n",
            "char_count2: 210\n",
            "i: 210  token: 。\n",
            "char_count2: 211\n",
            "i: 211  token: 醫\n",
            "char_count2: 212\n",
            "i: 212  token: 藥\n",
            "char_count2: 213\n",
            "i: 213  token: 學\n",
            "char_count2: 214\n",
            "i: 214  token: 方\n",
            "char_count2: 215\n",
            "i: 215  token: 面\n",
            "char_count2: 216\n",
            "i: 216  token: ，\n",
            "char_count2: 217\n",
            "i: 217  token: 史\n",
            "char_count2: 218\n",
            "i: 218  token: 稱\n",
            "char_count2: 219\n",
            "i: 219  token: 金\n",
            "char_count2: 220\n",
            "i: 220  token: 元\n",
            "char_count2: 221\n",
            "i: 221  token: 四\n",
            "char_count2: 222\n",
            "i: 222  token: 大\n",
            "char_count2: 223\n",
            "i: 223  token: 家\n",
            "char_count2: 224\n",
            "i: 224  token: 中\n",
            "char_count2: 225\n",
            "i: 225  token: 有\n",
            "char_count2: 226\n",
            "i: 226  token: 兩\n",
            "char_count2: 227\n",
            "i: 227  token: 位\n",
            "char_count2: 228\n",
            "i: 228  token: 生\n",
            "char_count2: 229\n",
            "i: 229  token: 活\n",
            "char_count2: 230\n",
            "i: 230  token: 在\n",
            "char_count2: 231\n",
            "i: 231  token: 蒙\n",
            "char_count2: 232\n",
            "i: 232  token: 元\n",
            "char_count2: 233\n",
            "i: 233  token: 時\n",
            "char_count2: 234\n",
            "i: 234  token: 期\n",
            "char_count2: 235\n",
            "i: 235  token: 。\n",
            "char_count2: 236\n",
            "i: 236  token: 李\n",
            "new_start2: 236\n",
            "char_count2: 237\n",
            "i: 237  token: [UNK]\n",
            "new_start 236\n",
            "new_end 237\n",
            "final prediction 李杲\n",
            "found [UNK] in prediction.\n",
            "original pred: 奧 運 進 場 時 「 [UNK] 」 比 「 [UNK] 」 先 進 場\n",
            "start: 258\n",
            "end: 272\n",
            "i: 0  token: 韓\n",
            "char_count2: 1\n",
            "i: 1  token: 國\n",
            "char_count2: 2\n",
            "i: 2  token: 國\n",
            "char_count2: 3\n",
            "i: 3  token: 家\n",
            "char_count2: 4\n",
            "i: 4  token: 足\n",
            "char_count2: 5\n",
            "i: 5  token: 球\n",
            "char_count2: 6\n",
            "i: 6  token: 隊\n",
            "char_count2: 7\n",
            "i: 7  token: ，\n",
            "char_count2: 8\n",
            "i: 8  token: 全\n",
            "char_count2: 9\n",
            "i: 9  token: 名\n",
            "char_count2: 10\n",
            "i: 10  token: 大\n",
            "char_count2: 11\n",
            "i: 11  token: 韓\n",
            "char_count2: 12\n",
            "i: 12  token: 民\n",
            "char_count2: 13\n",
            "i: 13  token: 國\n",
            "char_count2: 14\n",
            "i: 14  token: 足\n",
            "char_count2: 15\n",
            "i: 15  token: 球\n",
            "char_count2: 16\n",
            "i: 16  token: 國\n",
            "char_count2: 17\n",
            "i: 17  token: 家\n",
            "char_count2: 18\n",
            "i: 18  token: 代\n",
            "char_count2: 19\n",
            "i: 19  token: 表\n",
            "char_count2: 20\n",
            "i: 20  token: 隊\n",
            "char_count2: 21\n",
            "i: 21  token: ，\n",
            "char_count2: 22\n",
            "i: 22  token: 為\n",
            "char_count2: 23\n",
            "i: 23  token: 韓\n",
            "char_count2: 24\n",
            "i: 24  token: 國\n",
            "char_count2: 25\n",
            "i: 25  token: 足\n",
            "char_count2: 26\n",
            "i: 26  token: 球\n",
            "char_count2: 27\n",
            "i: 27  token: 協\n",
            "char_count2: 28\n",
            "i: 28  token: 會\n",
            "char_count2: 29\n",
            "i: 29  token: 所\n",
            "char_count2: 30\n",
            "i: 30  token: 於\n",
            "char_count2: 31\n",
            "i: 31  token: 1928\n",
            "char_count2: 32\n",
            "i: 32  token: 年\n",
            "char_count2: 33\n",
            "i: 33  token: 成\n",
            "char_count2: 34\n",
            "i: 34  token: 立\n",
            "char_count2: 35\n",
            "i: 35  token: ，\n",
            "char_count2: 36\n",
            "i: 36  token: 並\n",
            "char_count2: 37\n",
            "i: 37  token: 於\n",
            "char_count2: 38\n",
            "i: 38  token: 1948\n",
            "char_count2: 39\n",
            "i: 39  token: 年\n",
            "char_count2: 40\n",
            "i: 40  token: 加\n",
            "char_count2: 41\n",
            "i: 41  token: 入\n",
            "char_count2: 42\n",
            "i: 42  token: 國\n",
            "char_count2: 43\n",
            "i: 43  token: 際\n",
            "char_count2: 44\n",
            "i: 44  token: 足\n",
            "char_count2: 45\n",
            "i: 45  token: 球\n",
            "char_count2: 46\n",
            "i: 46  token: 總\n",
            "char_count2: 47\n",
            "i: 47  token: 會\n",
            "char_count2: 48\n",
            "i: 48  token: 。\n",
            "char_count2: 49\n",
            "i: 49  token: 韓\n",
            "char_count2: 50\n",
            "i: 50  token: 國\n",
            "char_count2: 51\n",
            "i: 51  token: 隊\n",
            "char_count2: 52\n",
            "i: 52  token: 是\n",
            "char_count2: 53\n",
            "i: 53  token: 眾\n",
            "char_count2: 54\n",
            "i: 54  token: 多\n",
            "char_count2: 55\n",
            "i: 55  token: 亞\n",
            "char_count2: 56\n",
            "i: 56  token: 洲\n",
            "char_count2: 57\n",
            "i: 57  token: 球\n",
            "char_count2: 58\n",
            "i: 58  token: 隊\n",
            "char_count2: 59\n",
            "i: 59  token: 中\n",
            "char_count2: 60\n",
            "i: 60  token: ，\n",
            "char_count2: 61\n",
            "i: 61  token: 打\n",
            "char_count2: 62\n",
            "i: 62  token: 入\n",
            "char_count2: 63\n",
            "i: 63  token: 世\n",
            "char_count2: 64\n",
            "i: 64  token: 界\n",
            "char_count2: 65\n",
            "i: 65  token: 盃\n",
            "char_count2: 66\n",
            "i: 66  token: 決\n",
            "char_count2: 67\n",
            "i: 67  token: 賽\n",
            "char_count2: 68\n",
            "i: 68  token: 周\n",
            "char_count2: 69\n",
            "i: 69  token: 次\n",
            "char_count2: 70\n",
            "i: 70  token: 數\n",
            "char_count2: 71\n",
            "i: 71  token: 最\n",
            "char_count2: 72\n",
            "i: 72  token: 多\n",
            "char_count2: 73\n",
            "i: 73  token: ，\n",
            "char_count2: 74\n",
            "i: 74  token: 直\n",
            "char_count2: 75\n",
            "i: 75  token: 至\n",
            "char_count2: 76\n",
            "i: 76  token: 2018\n",
            "char_count2: 77\n",
            "i: 77  token: 年\n",
            "char_count2: 78\n",
            "i: 78  token: 世\n",
            "char_count2: 79\n",
            "i: 79  token: 界\n",
            "char_count2: 80\n",
            "i: 80  token: 盃\n",
            "char_count2: 81\n",
            "i: 81  token: 他\n",
            "char_count2: 82\n",
            "i: 82  token: 們\n",
            "char_count2: 83\n",
            "i: 83  token: 已\n",
            "char_count2: 84\n",
            "i: 84  token: 成\n",
            "char_count2: 85\n",
            "i: 85  token: 功\n",
            "char_count2: 86\n",
            "i: 86  token: 十\n",
            "char_count2: 87\n",
            "i: 87  token: 次\n",
            "char_count2: 88\n",
            "i: 88  token: 打\n",
            "char_count2: 89\n",
            "i: 89  token: 入\n",
            "char_count2: 90\n",
            "i: 90  token: 世\n",
            "char_count2: 91\n",
            "i: 91  token: 界\n",
            "char_count2: 92\n",
            "i: 92  token: 盃\n",
            "char_count2: 93\n",
            "i: 93  token: 決\n",
            "char_count2: 94\n",
            "i: 94  token: 賽\n",
            "char_count2: 95\n",
            "i: 95  token: 周\n",
            "char_count2: 96\n",
            "i: 96  token: ，\n",
            "char_count2: 97\n",
            "i: 97  token: 而\n",
            "char_count2: 98\n",
            "i: 98  token: 且\n",
            "char_count2: 99\n",
            "i: 99  token: 自\n",
            "char_count2: 100\n",
            "i: 100  token: 1986\n",
            "char_count2: 101\n",
            "i: 101  token: 年\n",
            "char_count2: 102\n",
            "i: 102  token: 世\n",
            "char_count2: 103\n",
            "i: 103  token: 界\n",
            "char_count2: 104\n",
            "i: 104  token: 盃\n",
            "char_count2: 105\n",
            "i: 105  token: 開\n",
            "char_count2: 106\n",
            "i: 106  token: 始\n",
            "char_count2: 107\n",
            "i: 107  token: ，\n",
            "char_count2: 108\n",
            "i: 108  token: 韓\n",
            "char_count2: 109\n",
            "i: 109  token: 國\n",
            "char_count2: 110\n",
            "i: 110  token: 隊\n",
            "char_count2: 111\n",
            "i: 111  token: 從\n",
            "char_count2: 112\n",
            "i: 112  token: 未\n",
            "char_count2: 113\n",
            "i: 113  token: 缺\n",
            "char_count2: 114\n",
            "i: 114  token: 席\n",
            "char_count2: 115\n",
            "i: 115  token: 任\n",
            "char_count2: 116\n",
            "i: 116  token: 何\n",
            "char_count2: 117\n",
            "i: 117  token: 一\n",
            "char_count2: 118\n",
            "i: 118  token: 屆\n",
            "char_count2: 119\n",
            "i: 119  token: 決\n",
            "char_count2: 120\n",
            "i: 120  token: 賽\n",
            "char_count2: 121\n",
            "i: 121  token: 周\n",
            "char_count2: 122\n",
            "i: 122  token: 。\n",
            "char_count2: 123\n",
            "i: 123  token: 在\n",
            "char_count2: 124\n",
            "i: 124  token: 2002\n",
            "char_count2: 125\n",
            "i: 125  token: 年\n",
            "char_count2: 126\n",
            "i: 126  token: 世\n",
            "char_count2: 127\n",
            "i: 127  token: 界\n",
            "char_count2: 128\n",
            "i: 128  token: 盃\n",
            "char_count2: 129\n",
            "i: 129  token: ，\n",
            "char_count2: 130\n",
            "i: 130  token: 韓\n",
            "char_count2: 131\n",
            "i: 131  token: 國\n",
            "char_count2: 132\n",
            "i: 132  token: 淘\n",
            "char_count2: 133\n",
            "i: 133  token: 汰\n",
            "char_count2: 134\n",
            "i: 134  token: 了\n",
            "char_count2: 135\n",
            "i: 135  token: 葡\n",
            "char_count2: 136\n",
            "i: 136  token: 萄\n",
            "char_count2: 137\n",
            "i: 137  token: 牙\n",
            "char_count2: 138\n",
            "i: 138  token: 、\n",
            "char_count2: 139\n",
            "i: 139  token: 義\n",
            "char_count2: 140\n",
            "i: 140  token: 大\n",
            "char_count2: 141\n",
            "i: 141  token: 利\n",
            "char_count2: 142\n",
            "i: 142  token: 、\n",
            "char_count2: 143\n",
            "i: 143  token: 西\n",
            "char_count2: 144\n",
            "i: 144  token: 班\n",
            "char_count2: 145\n",
            "i: 145  token: 牙\n",
            "char_count2: 146\n",
            "i: 146  token: 三\n",
            "char_count2: 147\n",
            "i: 147  token: 支\n",
            "char_count2: 148\n",
            "i: 148  token: 歐\n",
            "char_count2: 149\n",
            "i: 149  token: 洲\n",
            "char_count2: 150\n",
            "i: 150  token: 強\n",
            "char_count2: 151\n",
            "i: 151  token: 隊\n",
            "char_count2: 152\n",
            "i: 152  token: ，\n",
            "char_count2: 153\n",
            "i: 153  token: 最\n",
            "char_count2: 154\n",
            "i: 154  token: 後\n",
            "char_count2: 155\n",
            "i: 155  token: 奪\n",
            "char_count2: 156\n",
            "i: 156  token: 得\n",
            "char_count2: 157\n",
            "i: 157  token: 了\n",
            "char_count2: 158\n",
            "i: 158  token: 殿\n",
            "char_count2: 159\n",
            "i: 159  token: 軍\n",
            "char_count2: 160\n",
            "i: 160  token: ，\n",
            "char_count2: 161\n",
            "i: 161  token: 取\n",
            "char_count2: 162\n",
            "i: 162  token: 得\n",
            "char_count2: 163\n",
            "i: 163  token: 亞\n",
            "char_count2: 164\n",
            "i: 164  token: 洲\n",
            "char_count2: 165\n",
            "i: 165  token: 球\n",
            "char_count2: 166\n",
            "i: 166  token: 隊\n",
            "char_count2: 167\n",
            "i: 167  token: 有\n",
            "char_count2: 168\n",
            "i: 168  token: 史\n",
            "char_count2: 169\n",
            "i: 169  token: 以\n",
            "char_count2: 170\n",
            "i: 170  token: 來\n",
            "char_count2: 171\n",
            "i: 171  token: 最\n",
            "char_count2: 172\n",
            "i: 172  token: 好\n",
            "char_count2: 173\n",
            "i: 173  token: 成\n",
            "char_count2: 174\n",
            "i: 174  token: 績\n",
            "char_count2: 175\n",
            "i: 175  token: 。\n",
            "char_count2: 176\n",
            "i: 176  token: 在\n",
            "char_count2: 177\n",
            "i: 177  token: 2010\n",
            "char_count2: 178\n",
            "i: 178  token: 年\n",
            "char_count2: 179\n",
            "i: 179  token: 世\n",
            "char_count2: 180\n",
            "i: 180  token: 界\n",
            "char_count2: 181\n",
            "i: 181  token: 盃\n",
            "char_count2: 182\n",
            "i: 182  token: ，\n",
            "char_count2: 183\n",
            "i: 183  token: 韓\n",
            "char_count2: 184\n",
            "i: 184  token: 國\n",
            "char_count2: 185\n",
            "i: 185  token: 也\n",
            "char_count2: 186\n",
            "i: 186  token: 在\n",
            "char_count2: 187\n",
            "i: 187  token: 首\n",
            "char_count2: 188\n",
            "i: 188  token: 圈\n",
            "char_count2: 189\n",
            "i: 189  token: 分\n",
            "char_count2: 190\n",
            "i: 190  token: 組\n",
            "char_count2: 191\n",
            "i: 191  token: 賽\n",
            "char_count2: 192\n",
            "i: 192  token: 壓\n",
            "char_count2: 193\n",
            "i: 193  token: 倒\n",
            "char_count2: 194\n",
            "i: 194  token: 希\n",
            "char_count2: 195\n",
            "i: 195  token: 臘\n",
            "char_count2: 196\n",
            "i: 196  token: 及\n",
            "char_count2: 197\n",
            "i: 197  token: 奈\n",
            "char_count2: 198\n",
            "i: 198  token: 及\n",
            "char_count2: 199\n",
            "i: 199  token: 利\n",
            "char_count2: 200\n",
            "i: 200  token: 亞\n",
            "char_count2: 201\n",
            "i: 201  token: 出\n",
            "char_count2: 202\n",
            "i: 202  token: 線\n",
            "char_count2: 203\n",
            "i: 203  token: 次\n",
            "char_count2: 204\n",
            "i: 204  token: 圈\n",
            "char_count2: 205\n",
            "i: 205  token: ，\n",
            "char_count2: 206\n",
            "i: 206  token: 再\n",
            "char_count2: 207\n",
            "i: 207  token: 次\n",
            "char_count2: 208\n",
            "i: 208  token: 晉\n",
            "char_count2: 209\n",
            "i: 209  token: 身\n",
            "char_count2: 210\n",
            "i: 210  token: 十\n",
            "char_count2: 211\n",
            "i: 211  token: 六\n",
            "char_count2: 212\n",
            "i: 212  token: 強\n",
            "char_count2: 213\n",
            "i: 213  token: ，\n",
            "char_count2: 214\n",
            "i: 214  token: 但\n",
            "char_count2: 215\n",
            "i: 215  token: 以\n",
            "char_count2: 216\n",
            "i: 216  token: 1\n",
            "char_count2: 217\n",
            "i: 217  token: -\n",
            "char_count2: 218\n",
            "i: 218  token: 2\n",
            "char_count2: 219\n",
            "i: 219  token: 敗\n",
            "char_count2: 220\n",
            "i: 220  token: 給\n",
            "char_count2: 221\n",
            "i: 221  token: 烏\n",
            "char_count2: 222\n",
            "i: 222  token: 拉\n",
            "char_count2: 223\n",
            "i: 223  token: 圭\n",
            "char_count2: 224\n",
            "i: 224  token: 出\n",
            "char_count2: 225\n",
            "i: 225  token: 局\n",
            "char_count2: 226\n",
            "i: 226  token: 。\n",
            "char_count2: 227\n",
            "i: 227  token: 2002\n",
            "char_count2: 228\n",
            "i: 228  token: 年\n",
            "char_count2: 229\n",
            "i: 229  token: 世\n",
            "char_count2: 230\n",
            "i: 230  token: 界\n",
            "char_count2: 231\n",
            "i: 231  token: 盃\n",
            "char_count2: 232\n",
            "i: 232  token: 時\n",
            "char_count2: 233\n",
            "i: 233  token: 南\n",
            "char_count2: 234\n",
            "i: 234  token: 韓\n",
            "char_count2: 235\n",
            "i: 235  token: 國\n",
            "char_count2: 236\n",
            "i: 236  token: 名\n",
            "char_count2: 237\n",
            "i: 237  token: 英\n",
            "char_count2: 238\n",
            "i: 238  token: 文\n",
            "char_count2: 239\n",
            "i: 239  token: 標\n",
            "char_count2: 240\n",
            "i: 240  token: 記\n",
            "char_count2: 241\n",
            "i: 241  token: 以\n",
            "char_count2: 242\n",
            "i: 242  token: [UNK]\n",
            "char_count1: 243\n",
            "i: 243  token: 參\n",
            "char_count2: 244\n",
            "i: 244  token: 加\n",
            "char_count2: 245\n",
            "i: 245  token: ，\n",
            "char_count2: 246\n",
            "i: 246  token: 其\n",
            "char_count2: 247\n",
            "i: 247  token: 原\n",
            "char_count2: 248\n",
            "i: 248  token: 因\n",
            "char_count2: 249\n",
            "i: 249  token: 是\n",
            "char_count2: 250\n",
            "i: 250  token: 在\n",
            "char_count2: 251\n",
            "i: 251  token: 日\n",
            "char_count2: 252\n",
            "i: 252  token: 治\n",
            "char_count2: 253\n",
            "i: 253  token: 時\n",
            "char_count2: 254\n",
            "i: 254  token: 代\n",
            "char_count2: 255\n",
            "i: 255  token: 時\n",
            "char_count2: 256\n",
            "i: 256  token: 因\n",
            "char_count2: 257\n",
            "i: 257  token: 為\n",
            "char_count2: 258\n",
            "i: 258  token: 奧\n",
            "new_start2: 258\n",
            "char_count2: 259\n",
            "i: 259  token: 運\n",
            "char_count2: 260\n",
            "i: 260  token: 進\n",
            "char_count2: 261\n",
            "i: 261  token: 場\n",
            "char_count2: 262\n",
            "i: 262  token: 時\n",
            "char_count2: 263\n",
            "i: 263  token: 「\n",
            "char_count2: 264\n",
            "i: 264  token: [UNK]\n",
            "char_count1: 265\n",
            "i: 265  token: 」\n",
            "char_count2: 266\n",
            "i: 266  token: 比\n",
            "char_count2: 267\n",
            "i: 267  token: 「\n",
            "char_count2: 268\n",
            "i: 268  token: [UNK]\n",
            "char_count1: 269\n",
            "i: 269  token: 」\n",
            "char_count2: 270\n",
            "i: 270  token: 先\n",
            "char_count2: 271\n",
            "i: 271  token: 進\n",
            "char_count2: 272\n",
            "i: 272  token: 場\n",
            "new_start 258\n",
            "new_end 272\n",
            "final prediction 英文標記以COREA參加，其原\n",
            "found [UNK] in prediction.\n",
            "original pred: 朱 允 [UNK]\n",
            "start: 18\n",
            "end: 20\n",
            "i: 0  token: 東\n",
            "char_count2: 1\n",
            "i: 1  token: 昌\n",
            "char_count2: 2\n",
            "i: 2  token: 之\n",
            "char_count2: 3\n",
            "i: 3  token: 戰\n",
            "char_count2: 4\n",
            "i: 4  token: ，\n",
            "char_count2: 5\n",
            "i: 5  token: 朱\n",
            "char_count2: 6\n",
            "i: 6  token: 棣\n",
            "char_count2: 7\n",
            "i: 7  token: 多\n",
            "char_count2: 8\n",
            "i: 8  token: 次\n",
            "char_count2: 9\n",
            "i: 9  token: 瀕\n",
            "char_count2: 10\n",
            "i: 10  token: 臨\n",
            "char_count2: 11\n",
            "i: 11  token: 險\n",
            "char_count2: 12\n",
            "i: 12  token: 境\n",
            "char_count2: 13\n",
            "i: 13  token: 。\n",
            "char_count2: 14\n",
            "i: 14  token: 但\n",
            "char_count2: 15\n",
            "i: 15  token: 是\n",
            "char_count2: 16\n",
            "i: 16  token: 由\n",
            "char_count2: 17\n",
            "i: 17  token: 於\n",
            "char_count2: 18\n",
            "i: 18  token: 朱\n",
            "new_start2: 18\n",
            "char_count2: 19\n",
            "i: 19  token: 允\n",
            "char_count2: 20\n",
            "i: 20  token: [UNK]\n",
            "new_start 18\n",
            "new_end 20\n",
            "final prediction 朱允炆\n",
            "found [UNK] in prediction.\n",
            "original pred: [UNK] 崎 八 幡 宮\n",
            "start: 146\n",
            "end: 150\n",
            "i: 0  token: 福\n",
            "char_count2: 1\n",
            "i: 1  token: 岡\n",
            "char_count2: 2\n",
            "i: 2  token: 市\n",
            "char_count2: 3\n",
            "i: 3  token: 內\n",
            "char_count2: 4\n",
            "i: 4  token: 有\n",
            "char_count2: 5\n",
            "i: 5  token: 眾\n",
            "char_count2: 6\n",
            "i: 6  token: 多\n",
            "char_count2: 7\n",
            "i: 7  token: 人\n",
            "char_count2: 8\n",
            "i: 8  token: 文\n",
            "char_count2: 9\n",
            "i: 9  token: 觀\n",
            "char_count2: 10\n",
            "i: 10  token: 光\n",
            "char_count2: 11\n",
            "i: 11  token: 景\n",
            "char_count2: 12\n",
            "i: 12  token: 點\n",
            "char_count2: 13\n",
            "i: 13  token: 。\n",
            "char_count2: 14\n",
            "i: 14  token: 位\n",
            "char_count2: 15\n",
            "i: 15  token: 於\n",
            "char_count2: 16\n",
            "i: 16  token: 福\n",
            "char_count2: 17\n",
            "i: 17  token: 岡\n",
            "char_count2: 18\n",
            "i: 18  token: 市\n",
            "char_count2: 19\n",
            "i: 19  token: 中\n",
            "char_count2: 20\n",
            "i: 20  token: 心\n",
            "char_count2: 21\n",
            "i: 21  token: 的\n",
            "char_count2: 22\n",
            "i: 22  token: 福\n",
            "char_count2: 23\n",
            "i: 23  token: 岡\n",
            "char_count2: 24\n",
            "i: 24  token: 城\n",
            "char_count2: 25\n",
            "i: 25  token: 是\n",
            "char_count2: 26\n",
            "i: 26  token: 日\n",
            "char_count2: 27\n",
            "i: 27  token: 本\n",
            "char_count2: 28\n",
            "i: 28  token: 100\n",
            "char_count2: 29\n",
            "i: 29  token: 名\n",
            "char_count2: 30\n",
            "i: 30  token: 城\n",
            "char_count2: 31\n",
            "i: 31  token: 之\n",
            "char_count2: 32\n",
            "i: 32  token: 一\n",
            "char_count2: 33\n",
            "i: 33  token: ，\n",
            "char_count2: 34\n",
            "i: 34  token: 且\n",
            "char_count2: 35\n",
            "i: 35  token: 平\n",
            "char_count2: 36\n",
            "i: 36  token: 安\n",
            "char_count2: 37\n",
            "i: 37  token: 時\n",
            "char_count2: 38\n",
            "i: 38  token: 代\n",
            "char_count2: 39\n",
            "i: 39  token: 的\n",
            "char_count2: 40\n",
            "i: 40  token: 外\n",
            "char_count2: 41\n",
            "i: 41  token: 交\n",
            "char_count2: 42\n",
            "i: 42  token: 設\n",
            "char_count2: 43\n",
            "i: 43  token: 施\n",
            "char_count2: 44\n",
            "i: 44  token: 鴻\n",
            "char_count2: 45\n",
            "i: 45  token: [UNK]\n",
            "char_count1: 46\n",
            "i: 46  token: 館\n",
            "char_count2: 47\n",
            "i: 47  token: 遺\n",
            "char_count2: 48\n",
            "i: 48  token: 跡\n",
            "char_count2: 49\n",
            "i: 49  token: 亦\n",
            "char_count2: 50\n",
            "i: 50  token: 位\n",
            "char_count2: 51\n",
            "i: 51  token: 於\n",
            "char_count2: 52\n",
            "i: 52  token: 福\n",
            "char_count2: 53\n",
            "i: 53  token: 岡\n",
            "char_count2: 54\n",
            "i: 54  token: 城\n",
            "char_count2: 55\n",
            "i: 55  token: 內\n",
            "char_count2: 56\n",
            "i: 56  token: 。\n",
            "char_count2: 57\n",
            "i: 57  token: 福\n",
            "char_count2: 58\n",
            "i: 58  token: 岡\n",
            "char_count2: 59\n",
            "i: 59  token: 城\n",
            "char_count2: 60\n",
            "i: 60  token: 西\n",
            "char_count2: 61\n",
            "i: 61  token: 側\n",
            "char_count2: 62\n",
            "i: 62  token: 的\n",
            "char_count2: 63\n",
            "i: 63  token: 大\n",
            "char_count2: 64\n",
            "i: 64  token: 濠\n",
            "char_count2: 65\n",
            "i: 65  token: 公\n",
            "char_count2: 66\n",
            "i: 66  token: 園\n",
            "char_count2: 67\n",
            "i: 67  token: 聚\n",
            "char_count2: 68\n",
            "i: 68  token: 集\n",
            "char_count2: 69\n",
            "i: 69  token: 了\n",
            "char_count2: 70\n",
            "i: 70  token: 眾\n",
            "char_count2: 71\n",
            "i: 71  token: 多\n",
            "char_count2: 72\n",
            "i: 72  token: 文\n",
            "char_count2: 73\n",
            "i: 73  token: 化\n",
            "char_count2: 74\n",
            "i: 74  token: 設\n",
            "char_count2: 75\n",
            "i: 75  token: 施\n",
            "char_count2: 76\n",
            "i: 76  token: ，\n",
            "char_count2: 77\n",
            "i: 77  token: 是\n",
            "char_count2: 78\n",
            "i: 78  token: 日\n",
            "char_count2: 79\n",
            "i: 79  token: 本\n",
            "char_count2: 80\n",
            "i: 80  token: 著\n",
            "char_count2: 81\n",
            "i: 81  token: 名\n",
            "char_count2: 82\n",
            "i: 82  token: 的\n",
            "char_count2: 83\n",
            "i: 83  token: 水\n",
            "char_count2: 84\n",
            "i: 84  token: 景\n",
            "char_count2: 85\n",
            "i: 85  token: 公\n",
            "char_count2: 86\n",
            "i: 86  token: 園\n",
            "char_count2: 87\n",
            "i: 87  token: ，\n",
            "char_count2: 88\n",
            "i: 88  token: 並\n",
            "char_count2: 89\n",
            "i: 89  token: 以\n",
            "char_count2: 90\n",
            "i: 90  token: 每\n",
            "char_count2: 91\n",
            "i: 91  token: 年\n",
            "char_count2: 92\n",
            "i: 92  token: 8\n",
            "char_count2: 93\n",
            "i: 93  token: 月\n",
            "char_count2: 94\n",
            "i: 94  token: 1\n",
            "char_count2: 95\n",
            "i: 95  token: 日\n",
            "char_count2: 96\n",
            "i: 96  token: 舉\n",
            "char_count2: 97\n",
            "i: 97  token: 辦\n",
            "char_count2: 98\n",
            "i: 98  token: 的\n",
            "char_count2: 99\n",
            "i: 99  token: 煙\n",
            "char_count2: 100\n",
            "i: 100  token: 花\n",
            "char_count2: 101\n",
            "i: 101  token: 大\n",
            "char_count2: 102\n",
            "i: 102  token: 會\n",
            "char_count2: 103\n",
            "i: 103  token: 而\n",
            "char_count2: 104\n",
            "i: 104  token: 著\n",
            "char_count2: 105\n",
            "i: 105  token: 稱\n",
            "char_count2: 106\n",
            "i: 106  token: 。\n",
            "char_count2: 107\n",
            "i: 107  token: 香\n",
            "char_count2: 108\n",
            "i: 108  token: 椎\n",
            "char_count2: 109\n",
            "i: 109  token: 宮\n",
            "char_count2: 110\n",
            "i: 110  token: 在\n",
            "char_count2: 111\n",
            "i: 111  token: 神\n",
            "char_count2: 112\n",
            "i: 112  token: 道\n",
            "char_count2: 113\n",
            "i: 113  token: 教\n",
            "char_count2: 114\n",
            "i: 114  token: 中\n",
            "char_count2: 115\n",
            "i: 115  token: 擁\n",
            "char_count2: 116\n",
            "i: 116  token: 有\n",
            "char_count2: 117\n",
            "i: 117  token: 官\n",
            "char_count2: 118\n",
            "i: 118  token: 幣\n",
            "char_count2: 119\n",
            "i: 119  token: 大\n",
            "char_count2: 120\n",
            "i: 120  token: 社\n",
            "char_count2: 121\n",
            "i: 121  token: 的\n",
            "char_count2: 122\n",
            "i: 122  token: 崇\n",
            "char_count2: 123\n",
            "i: 123  token: 高\n",
            "char_count2: 124\n",
            "i: 124  token: 地\n",
            "char_count2: 125\n",
            "i: 125  token: 位\n",
            "char_count2: 126\n",
            "i: 126  token: ，\n",
            "char_count2: 127\n",
            "i: 127  token: 本\n",
            "char_count2: 128\n",
            "i: 128  token: 殿\n",
            "char_count2: 129\n",
            "i: 129  token: 建\n",
            "char_count2: 130\n",
            "i: 130  token: 築\n",
            "char_count2: 131\n",
            "i: 131  token: 是\n",
            "char_count2: 132\n",
            "i: 132  token: 日\n",
            "char_count2: 133\n",
            "i: 133  token: 本\n",
            "char_count2: 134\n",
            "i: 134  token: 的\n",
            "char_count2: 135\n",
            "i: 135  token: 重\n",
            "char_count2: 136\n",
            "i: 136  token: 要\n",
            "char_count2: 137\n",
            "i: 137  token: 文\n",
            "char_count2: 138\n",
            "i: 138  token: 化\n",
            "char_count2: 139\n",
            "i: 139  token: 財\n",
            "char_count2: 140\n",
            "i: 140  token: 。\n",
            "char_count2: 141\n",
            "i: 141  token: [UNK]\n",
            "char_count1: 142\n",
            "i: 142  token: 崎\n",
            "char_count2: 143\n",
            "i: 143  token: 宮\n",
            "char_count2: 144\n",
            "i: 144  token: 又\n",
            "char_count2: 145\n",
            "i: 145  token: 稱\n",
            "char_count2: 146\n",
            "i: 146  token: [UNK]\n",
            "new_start1: 146\n",
            "char_count1: 147\n",
            "i: 147  token: 崎\n",
            "char_count2: 148\n",
            "i: 148  token: 八\n",
            "char_count2: 149\n",
            "i: 149  token: 幡\n",
            "char_count2: 150\n",
            "i: 150  token: 宮\n",
            "new_start 146\n",
            "new_end 150\n",
            "final prediction 又稱筥崎八\n",
            "found [UNK] in prediction.\n",
            "original pred: 與 慕 容 [UNK] 雙 方 不 和\n",
            "start: 35\n",
            "end: 42\n",
            "i: 0  token: 吐\n",
            "char_count2: 1\n",
            "i: 1  token: 谷\n",
            "char_count2: 2\n",
            "i: 2  token: 渾\n",
            "char_count2: 3\n",
            "i: 3  token: 原\n",
            "char_count2: 4\n",
            "i: 4  token: 為\n",
            "char_count2: 5\n",
            "i: 5  token: 鮮\n",
            "char_count2: 6\n",
            "i: 6  token: 卑\n",
            "char_count2: 7\n",
            "i: 7  token: 慕\n",
            "char_count2: 8\n",
            "i: 8  token: 容\n",
            "char_count2: 9\n",
            "i: 9  token: 部\n",
            "char_count2: 10\n",
            "i: 10  token: 的\n",
            "char_count2: 11\n",
            "i: 11  token: 一\n",
            "char_count2: 12\n",
            "i: 12  token: 支\n",
            "char_count2: 13\n",
            "i: 13  token: ，\n",
            "char_count2: 14\n",
            "i: 14  token: 283\n",
            "char_count2: 15\n",
            "i: 15  token: 年\n",
            "char_count2: 16\n",
            "i: 16  token: 鮮\n",
            "char_count2: 17\n",
            "i: 17  token: 卑\n",
            "char_count2: 18\n",
            "i: 18  token: 單\n",
            "char_count2: 19\n",
            "i: 19  token: 于\n",
            "char_count2: 20\n",
            "i: 20  token: 慕\n",
            "char_count2: 21\n",
            "i: 21  token: 容\n",
            "char_count2: 22\n",
            "i: 22  token: 涉\n",
            "char_count2: 23\n",
            "i: 23  token: 歸\n",
            "char_count2: 24\n",
            "i: 24  token: 的\n",
            "char_count2: 25\n",
            "i: 25  token: 庶\n",
            "char_count2: 26\n",
            "i: 26  token: 長\n",
            "char_count2: 27\n",
            "i: 27  token: 子\n",
            "char_count2: 28\n",
            "i: 28  token: 慕\n",
            "char_count2: 29\n",
            "i: 29  token: 容\n",
            "char_count2: 30\n",
            "i: 30  token: 吐\n",
            "char_count2: 31\n",
            "i: 31  token: 谷\n",
            "char_count2: 32\n",
            "i: 32  token: 渾\n",
            "char_count2: 33\n",
            "i: 33  token: ，\n",
            "char_count2: 34\n",
            "i: 34  token: 因\n",
            "char_count2: 35\n",
            "i: 35  token: 與\n",
            "new_start2: 35\n",
            "char_count2: 36\n",
            "i: 36  token: 慕\n",
            "char_count2: 37\n",
            "i: 37  token: 容\n",
            "char_count2: 38\n",
            "i: 38  token: [UNK]\n",
            "char_count1: 39\n",
            "i: 39  token: 雙\n",
            "char_count2: 40\n",
            "i: 40  token: 方\n",
            "char_count2: 41\n",
            "i: 41  token: 不\n",
            "char_count2: 42\n",
            "i: 42  token: 和\n",
            "new_start 35\n",
            "new_end 42\n",
            "final prediction ，因與慕容廆雙方\n",
            "found [UNK] in prediction.\n",
            "original pred: [UNK] [UNK]\n",
            "start: 372\n",
            "end: 373\n",
            "i: 0  token: 加\n",
            "char_count2: 1\n",
            "i: 1  token: 拿\n",
            "char_count2: 2\n",
            "i: 2  token: 大\n",
            "char_count2: 3\n",
            "i: 3  token: 在\n",
            "char_count2: 4\n",
            "i: 4  token: 1939\n",
            "char_count2: 5\n",
            "i: 5  token: 年\n",
            "char_count2: 6\n",
            "i: 6  token: 參\n",
            "char_count2: 7\n",
            "i: 7  token: 加\n",
            "char_count2: 8\n",
            "i: 8  token: 第\n",
            "char_count2: 9\n",
            "i: 9  token: 二\n",
            "char_count2: 10\n",
            "i: 10  token: 次\n",
            "char_count2: 11\n",
            "i: 11  token: 世\n",
            "char_count2: 12\n",
            "i: 12  token: 界\n",
            "char_count2: 13\n",
            "i: 13  token: 大\n",
            "char_count2: 14\n",
            "i: 14  token: 戰\n",
            "char_count2: 15\n",
            "i: 15  token: 。\n",
            "char_count2: 16\n",
            "i: 16  token: 溫\n",
            "char_count2: 17\n",
            "i: 17  token: 尼\n",
            "char_count2: 18\n",
            "i: 18  token: 伯\n",
            "char_count2: 19\n",
            "i: 19  token: 是\n",
            "char_count2: 20\n",
            "i: 20  token: 英\n",
            "char_count2: 21\n",
            "i: 21  token: 國\n",
            "char_count2: 22\n",
            "i: 22  token: 聯\n",
            "char_count2: 23\n",
            "i: 23  token: 邦\n",
            "char_count2: 24\n",
            "i: 24  token: 空\n",
            "char_count2: 25\n",
            "i: 25  token: 軍\n",
            "char_count2: 26\n",
            "i: 26  token: 培\n",
            "char_count2: 27\n",
            "i: 27  token: 訓\n",
            "char_count2: 28\n",
            "i: 28  token: 計\n",
            "char_count2: 29\n",
            "i: 29  token: 劃\n",
            "char_count2: 30\n",
            "i: 30  token: 的\n",
            "char_count2: 31\n",
            "i: 31  token: 主\n",
            "char_count2: 32\n",
            "i: 32  token: 要\n",
            "char_count2: 33\n",
            "i: 33  token: 指\n",
            "char_count2: 34\n",
            "i: 34  token: 揮\n",
            "char_count2: 35\n",
            "i: 35  token: 部\n",
            "char_count2: 36\n",
            "i: 36  token: 之\n",
            "char_count2: 37\n",
            "i: 37  token: 一\n",
            "char_count2: 38\n",
            "i: 38  token: ，\n",
            "char_count2: 39\n",
            "i: 39  token: 主\n",
            "char_count2: 40\n",
            "i: 40  token: 要\n",
            "char_count2: 41\n",
            "i: 41  token: 訓\n",
            "char_count2: 42\n",
            "i: 42  token: 練\n",
            "char_count2: 43\n",
            "i: 43  token: 戰\n",
            "char_count2: 44\n",
            "i: 44  token: 鬥\n",
            "char_count2: 45\n",
            "i: 45  token: 機\n",
            "char_count2: 46\n",
            "i: 46  token: 飛\n",
            "char_count2: 47\n",
            "i: 47  token: 行\n",
            "char_count2: 48\n",
            "i: 48  token: 員\n",
            "char_count2: 49\n",
            "i: 49  token: 。\n",
            "char_count2: 50\n",
            "i: 50  token: 在\n",
            "char_count2: 51\n",
            "i: 51  token: 曼\n",
            "char_count2: 52\n",
            "i: 52  token: 尼\n",
            "char_count2: 53\n",
            "i: 53  token: 托\n",
            "char_count2: 54\n",
            "i: 54  token: 巴\n",
            "char_count2: 55\n",
            "i: 55  token: 各\n",
            "char_count2: 56\n",
            "i: 56  token: 地\n",
            "char_count2: 57\n",
            "i: 57  token: 都\n",
            "char_count2: 58\n",
            "i: 58  token: 有\n",
            "char_count2: 59\n",
            "i: 59  token: 飛\n",
            "char_count2: 60\n",
            "i: 60  token: 行\n",
            "char_count2: 61\n",
            "i: 61  token: 訓\n",
            "char_count2: 62\n",
            "i: 62  token: 練\n",
            "char_count2: 63\n",
            "i: 63  token: 學\n",
            "char_count2: 64\n",
            "i: 64  token: 校\n",
            "char_count2: 65\n",
            "i: 65  token: 。\n",
            "char_count2: 66\n",
            "i: 66  token: 幾\n",
            "char_count2: 67\n",
            "i: 67  token: 個\n",
            "char_count2: 68\n",
            "i: 68  token: 曼\n",
            "char_count2: 69\n",
            "i: 69  token: 尼\n",
            "char_count2: 70\n",
            "i: 70  token: 托\n",
            "char_count2: 71\n",
            "i: 71  token: 巴\n",
            "char_count2: 72\n",
            "i: 72  token: 的\n",
            "char_count2: 73\n",
            "i: 73  token: 團\n",
            "char_count2: 74\n",
            "i: 74  token: 部\n",
            "char_count2: 75\n",
            "i: 75  token: 署\n",
            "char_count2: 76\n",
            "i: 76  token: 到\n",
            "char_count2: 77\n",
            "i: 77  token: 了\n",
            "char_count2: 78\n",
            "i: 78  token: 海\n",
            "char_count2: 79\n",
            "i: 79  token: 外\n",
            "char_count2: 80\n",
            "i: 80  token: ，\n",
            "char_count2: 81\n",
            "i: 81  token: 包\n",
            "char_count2: 82\n",
            "i: 82  token: 括\n",
            "char_count2: 83\n",
            "i: 83  token: 帕\n",
            "char_count2: 84\n",
            "i: 84  token: 特\n",
            "char_count2: 85\n",
            "i: 85  token: 里\n",
            "char_count2: 86\n",
            "i: 86  token: 夏\n",
            "char_count2: 87\n",
            "i: 87  token: 公\n",
            "char_count2: 88\n",
            "i: 88  token: 主\n",
            "char_count2: 89\n",
            "i: 89  token: 加\n",
            "char_count2: 90\n",
            "i: 90  token: 拿\n",
            "char_count2: 91\n",
            "i: 91  token: 大\n",
            "char_count2: 92\n",
            "i: 92  token: 輕\n",
            "char_count2: 93\n",
            "i: 93  token: 步\n",
            "char_count2: 94\n",
            "i: 94  token: 兵\n",
            "char_count2: 95\n",
            "i: 95  token: 團\n",
            "char_count2: 96\n",
            "i: 96  token: 。\n",
            "char_count2: 97\n",
            "i: 97  token: 此\n",
            "char_count2: 98\n",
            "i: 98  token: 外\n",
            "char_count2: 99\n",
            "i: 99  token: ，\n",
            "char_count2: 100\n",
            "i: 100  token: 為\n",
            "char_count2: 101\n",
            "i: 101  token: 了\n",
            "char_count2: 102\n",
            "i: 102  token: 為\n",
            "char_count2: 103\n",
            "i: 103  token: 戰\n",
            "char_count2: 104\n",
            "i: 104  token: 爭\n",
            "char_count2: 105\n",
            "i: 105  token: 籌\n",
            "char_count2: 106\n",
            "i: 106  token: 集\n",
            "char_count2: 107\n",
            "i: 107  token: 資\n",
            "char_count2: 108\n",
            "i: 108  token: 金\n",
            "char_count2: 109\n",
            "i: 109  token: ，\n",
            "char_count2: 110\n",
            "i: 110  token: 勝\n",
            "char_count2: 111\n",
            "i: 111  token: 利\n",
            "char_count2: 112\n",
            "i: 112  token: 貸\n",
            "char_count2: 113\n",
            "i: 113  token: 款\n",
            "char_count2: 114\n",
            "i: 114  token: 運\n",
            "char_count2: 115\n",
            "i: 115  token: 動\n",
            "char_count2: 116\n",
            "i: 116  token: 在\n",
            "char_count2: 117\n",
            "i: 117  token: 1942\n",
            "char_count2: 118\n",
            "i: 118  token: 年\n",
            "char_count2: 119\n",
            "i: 119  token: 組\n",
            "char_count2: 120\n",
            "i: 120  token: 織\n",
            "char_count2: 121\n",
            "i: 121  token: 了\n",
            "char_count2: 122\n",
            "i: 122  token: 「\n",
            "char_count2: 123\n",
            "i: 123  token: [UNK]\n",
            "char_count1: 124\n",
            "i: 124  token: [UNK]\n",
            "char_count1: 125\n",
            "i: 125  token: 」\n",
            "char_count2: 126\n",
            "i: 126  token: 活\n",
            "char_count2: 127\n",
            "i: 127  token: 動\n",
            "char_count2: 128\n",
            "i: 128  token: 。\n",
            "char_count2: 129\n",
            "i: 129  token: 該\n",
            "char_count2: 130\n",
            "i: 130  token: 活\n",
            "char_count2: 131\n",
            "i: 131  token: 動\n",
            "char_count2: 132\n",
            "i: 132  token: 模\n",
            "char_count2: 133\n",
            "i: 133  token: 擬\n",
            "char_count2: 134\n",
            "i: 134  token: 了\n",
            "char_count2: 135\n",
            "i: 135  token: 納\n",
            "char_count2: 136\n",
            "i: 136  token: 粹\n",
            "char_count2: 137\n",
            "i: 137  token: 侵\n",
            "char_count2: 138\n",
            "i: 138  token: 略\n",
            "char_count2: 139\n",
            "i: 139  token: 和\n",
            "char_count2: 140\n",
            "i: 140  token: 占\n",
            "char_count2: 141\n",
            "i: 141  token: 領\n",
            "char_count2: 142\n",
            "i: 142  token: 曼\n",
            "char_count2: 143\n",
            "i: 143  token: 尼\n",
            "char_count2: 144\n",
            "i: 144  token: 托\n",
            "char_count2: 145\n",
            "i: 145  token: 巴\n",
            "char_count2: 146\n",
            "i: 146  token: 的\n",
            "char_count2: 147\n",
            "i: 147  token: 過\n",
            "char_count2: 148\n",
            "i: 148  token: 程\n",
            "char_count2: 149\n",
            "i: 149  token: 及\n",
            "char_count2: 150\n",
            "i: 150  token: 後\n",
            "char_count2: 151\n",
            "i: 151  token: 果\n",
            "char_count2: 152\n",
            "i: 152  token: ，\n",
            "char_count2: 153\n",
            "i: 153  token: 並\n",
            "char_count2: 154\n",
            "i: 154  token: 最\n",
            "char_count2: 155\n",
            "i: 155  token: 終\n",
            "char_count2: 156\n",
            "i: 156  token: 籌\n",
            "char_count2: 157\n",
            "i: 157  token: 集\n",
            "char_count2: 158\n",
            "i: 158  token: 了\n",
            "char_count2: 159\n",
            "i: 159  token: 超\n",
            "char_count2: 160\n",
            "i: 160  token: 過\n",
            "char_count2: 161\n",
            "i: 161  token: 6\n",
            "char_count2: 162\n",
            "i: 162  token: ,\n",
            "char_count2: 163\n",
            "i: 163  token: 500\n",
            "char_count2: 164\n",
            "i: 164  token: 萬\n",
            "char_count2: 165\n",
            "i: 165  token: 加\n",
            "char_count2: 166\n",
            "i: 166  token: 元\n",
            "char_count2: 167\n",
            "i: 167  token: 。\n",
            "char_count2: 168\n",
            "i: 168  token: 溫\n",
            "char_count2: 169\n",
            "i: 169  token: 尼\n",
            "char_count2: 170\n",
            "i: 170  token: 伯\n",
            "char_count2: 171\n",
            "i: 171  token: 在\n",
            "char_count2: 172\n",
            "i: 172  token: 1950\n",
            "char_count2: 173\n",
            "i: 173  token: 年\n",
            "char_count2: 174\n",
            "i: 174  token: 紅\n",
            "char_count2: 175\n",
            "i: 175  token: 河\n",
            "char_count2: 176\n",
            "i: 176  token: 洪\n",
            "char_count2: 177\n",
            "i: 177  token: 水\n",
            "char_count2: 178\n",
            "i: 178  token: 期\n",
            "char_count2: 179\n",
            "i: 179  token: 間\n",
            "char_count2: 180\n",
            "i: 180  token: 幾\n",
            "char_count2: 181\n",
            "i: 181  token: 乎\n",
            "char_count2: 182\n",
            "i: 182  token: 被\n",
            "char_count2: 183\n",
            "i: 183  token: 淹\n",
            "char_count2: 184\n",
            "i: 184  token: 沒\n",
            "char_count2: 185\n",
            "i: 185  token: ，\n",
            "char_count2: 186\n",
            "i: 186  token: 不\n",
            "char_count2: 187\n",
            "i: 187  token: 得\n",
            "char_count2: 188\n",
            "i: 188  token: 不\n",
            "char_count2: 189\n",
            "i: 189  token: 疏\n",
            "char_count2: 190\n",
            "i: 190  token: 散\n",
            "char_count2: 191\n",
            "i: 191  token: 部\n",
            "char_count2: 192\n",
            "i: 192  token: 分\n",
            "char_count2: 193\n",
            "i: 193  token: 居\n",
            "char_count2: 194\n",
            "i: 194  token: 民\n",
            "char_count2: 195\n",
            "i: 195  token: 。\n",
            "char_count2: 196\n",
            "i: 196  token: 那\n",
            "char_count2: 197\n",
            "i: 197  token: 一\n",
            "char_count2: 198\n",
            "i: 198  token: 年\n",
            "char_count2: 199\n",
            "i: 199  token: ，\n",
            "char_count2: 200\n",
            "i: 200  token: 紅\n",
            "char_count2: 201\n",
            "i: 201  token: 河\n",
            "char_count2: 202\n",
            "i: 202  token: 水\n",
            "char_count2: 203\n",
            "i: 203  token: 位\n",
            "char_count2: 204\n",
            "i: 204  token: 達\n",
            "char_count2: 205\n",
            "i: 205  token: 到\n",
            "char_count2: 206\n",
            "i: 206  token: 了\n",
            "char_count2: 207\n",
            "i: 207  token: 自\n",
            "char_count2: 208\n",
            "i: 208  token: 186\n",
            "char_count2: 209\n",
            "i: 209  token: ##1\n",
            "char_count2: 210\n",
            "i: 210  token: 年\n",
            "char_count2: 211\n",
            "i: 211  token: 以\n",
            "char_count2: 212\n",
            "i: 212  token: 來\n",
            "char_count2: 213\n",
            "i: 213  token: 的\n",
            "char_count2: 214\n",
            "i: 214  token: 最\n",
            "char_count2: 215\n",
            "i: 215  token: 高\n",
            "char_count2: 216\n",
            "i: 216  token: 水\n",
            "char_count2: 217\n",
            "i: 217  token: 平\n",
            "char_count2: 218\n",
            "i: 218  token: ，\n",
            "char_count2: 219\n",
            "i: 219  token: 洪\n",
            "char_count2: 220\n",
            "i: 220  token: 水\n",
            "char_count2: 221\n",
            "i: 221  token: 淹\n",
            "char_count2: 222\n",
            "i: 222  token: 沒\n",
            "char_count2: 223\n",
            "i: 223  token: 了\n",
            "char_count2: 224\n",
            "i: 224  token: 紅\n",
            "char_count2: 225\n",
            "i: 225  token: 河\n",
            "char_count2: 226\n",
            "i: 226  token: 谷\n",
            "char_count2: 227\n",
            "i: 227  token: 的\n",
            "char_count2: 228\n",
            "i: 228  token: 絕\n",
            "char_count2: 229\n",
            "i: 229  token: 大\n",
            "char_count2: 230\n",
            "i: 230  token: 部\n",
            "char_count2: 231\n",
            "i: 231  token: 分\n",
            "char_count2: 232\n",
            "i: 232  token: 。\n",
            "char_count2: 233\n",
            "i: 233  token: 洪\n",
            "char_count2: 234\n",
            "i: 234  token: 水\n",
            "char_count2: 235\n",
            "i: 235  token: 造\n",
            "char_count2: 236\n",
            "i: 236  token: 成\n",
            "char_count2: 237\n",
            "i: 237  token: 的\n",
            "char_count2: 238\n",
            "i: 238  token: 巨\n",
            "char_count2: 239\n",
            "i: 239  token: 大\n",
            "char_count2: 240\n",
            "i: 240  token: 損\n",
            "char_count2: 241\n",
            "i: 241  token: 失\n",
            "char_count2: 242\n",
            "i: 242  token: 促\n",
            "char_count2: 243\n",
            "i: 243  token: 使\n",
            "char_count2: 244\n",
            "i: 244  token: 時\n",
            "char_count2: 245\n",
            "i: 245  token: 任\n",
            "char_count2: 246\n",
            "i: 246  token: 總\n",
            "char_count2: 247\n",
            "i: 247  token: 理\n",
            "char_count2: 248\n",
            "i: 248  token: [UNK]\n",
            "char_count1: 249\n",
            "i: 249  token: [UNK]\n",
            "char_count1: 250\n",
            "i: 250  token: 推\n",
            "char_count2: 251\n",
            "i: 251  token: 動\n",
            "char_count2: 252\n",
            "i: 252  token: 建\n",
            "char_count2: 253\n",
            "i: 253  token: 設\n",
            "char_count2: 254\n",
            "i: 254  token: 紅\n",
            "char_count2: 255\n",
            "i: 255  token: 河\n",
            "char_count2: 256\n",
            "i: 256  token: 泄\n",
            "char_count2: 257\n",
            "i: 257  token: 洪\n",
            "char_count2: 258\n",
            "i: 258  token: 水\n",
            "char_count2: 259\n",
            "i: 259  token: 道\n",
            "char_count2: 260\n",
            "i: 260  token: 。\n",
            "char_count2: 261\n",
            "i: 261  token: 經\n",
            "char_count2: 262\n",
            "i: 262  token: 過\n",
            "char_count2: 263\n",
            "i: 263  token: 了\n",
            "char_count2: 264\n",
            "i: 264  token: 六\n",
            "char_count2: 265\n",
            "i: 265  token: 年\n",
            "char_count2: 266\n",
            "i: 266  token: 的\n",
            "char_count2: 267\n",
            "i: 267  token: 施\n",
            "char_count2: 268\n",
            "i: 268  token: 工\n",
            "char_count2: 269\n",
            "i: 269  token: ，\n",
            "char_count2: 270\n",
            "i: 270  token: 水\n",
            "char_count2: 271\n",
            "i: 271  token: 道\n",
            "char_count2: 272\n",
            "i: 272  token: 於\n",
            "char_count2: 273\n",
            "i: 273  token: 在\n",
            "char_count2: 274\n",
            "i: 274  token: 1968\n",
            "char_count2: 275\n",
            "i: 275  token: 年\n",
            "char_count2: 276\n",
            "i: 276  token: 竣\n",
            "char_count2: 277\n",
            "i: 277  token: 工\n",
            "char_count2: 278\n",
            "i: 278  token: 。\n",
            "char_count2: 279\n",
            "i: 279  token: 在\n",
            "char_count2: 280\n",
            "i: 280  token: 溫\n",
            "char_count2: 281\n",
            "i: 281  token: 尼\n",
            "char_count2: 282\n",
            "i: 282  token: 伯\n",
            "char_count2: 283\n",
            "i: 283  token: 南\n",
            "char_count2: 284\n",
            "i: 284  token: 部\n",
            "char_count2: 285\n",
            "i: 285  token: 的\n",
            "char_count2: 286\n",
            "i: 286  token: 八\n",
            "char_count2: 287\n",
            "i: 287  token: 個\n",
            "char_count2: 288\n",
            "i: 288  token: 城\n",
            "char_count2: 289\n",
            "i: 289  token: 鎮\n",
            "char_count2: 290\n",
            "i: 290  token: 豎\n",
            "char_count2: 291\n",
            "i: 291  token: 立\n",
            "char_count2: 292\n",
            "i: 292  token: 了\n",
            "char_count2: 293\n",
            "i: 293  token: 永\n",
            "char_count2: 294\n",
            "i: 294  token: 久\n",
            "char_count2: 295\n",
            "i: 295  token: 堤\n",
            "char_count2: 296\n",
            "i: 296  token: 壩\n",
            "char_count2: 297\n",
            "i: 297  token: ，\n",
            "char_count2: 298\n",
            "i: 298  token: 在\n",
            "char_count2: 299\n",
            "i: 299  token: 溫\n",
            "char_count2: 300\n",
            "i: 300  token: 尼\n",
            "char_count2: 301\n",
            "i: 301  token: 伯\n",
            "char_count2: 302\n",
            "i: 302  token: 地\n",
            "char_count2: 303\n",
            "i: 303  token: 區\n",
            "char_count2: 304\n",
            "i: 304  token: 建\n",
            "char_count2: 305\n",
            "i: 305  token: 造\n",
            "char_count2: 306\n",
            "i: 306  token: 了\n",
            "char_count2: 307\n",
            "i: 307  token: 粘\n",
            "char_count2: 308\n",
            "i: 308  token: 土\n",
            "char_count2: 309\n",
            "i: 309  token: 土\n",
            "char_count2: 310\n",
            "i: 310  token: 質\n",
            "char_count2: 311\n",
            "i: 311  token: 的\n",
            "char_count2: 312\n",
            "i: 312  token: 堤\n",
            "char_count2: 313\n",
            "i: 313  token: 壩\n",
            "char_count2: 314\n",
            "i: 314  token: 和\n",
            "char_count2: 315\n",
            "i: 315  token: 引\n",
            "char_count2: 316\n",
            "i: 316  token: 水\n",
            "char_count2: 317\n",
            "i: 317  token: 壩\n",
            "char_count2: 318\n",
            "i: 318  token: 。\n",
            "char_count2: 319\n",
            "i: 319  token: 1997\n",
            "char_count2: 320\n",
            "i: 320  token: 年\n",
            "char_count2: 321\n",
            "i: 321  token: ，\n",
            "char_count2: 322\n",
            "i: 322  token: 「\n",
            "char_count2: 323\n",
            "i: 323  token: 世\n",
            "char_count2: 324\n",
            "i: 324  token: 紀\n",
            "char_count2: 325\n",
            "i: 325  token: 洪\n",
            "char_count2: 326\n",
            "i: 326  token: 水\n",
            "char_count2: 327\n",
            "i: 327  token: 」\n",
            "char_count2: 328\n",
            "i: 328  token: 在\n",
            "char_count2: 329\n",
            "i: 329  token: 曼\n",
            "char_count2: 330\n",
            "i: 330  token: 尼\n",
            "char_count2: 331\n",
            "i: 331  token: 托\n",
            "char_count2: 332\n",
            "i: 332  token: 巴\n",
            "char_count2: 333\n",
            "i: 333  token: 造\n",
            "char_count2: 334\n",
            "i: 334  token: 成\n",
            "char_count2: 335\n",
            "i: 335  token: 了\n",
            "char_count2: 336\n",
            "i: 336  token: 超\n",
            "char_count2: 337\n",
            "i: 337  token: 過\n",
            "char_count2: 338\n",
            "i: 338  token: 4\n",
            "char_count2: 339\n",
            "i: 339  token: 億\n",
            "char_count2: 340\n",
            "i: 340  token: 美\n",
            "char_count2: 341\n",
            "i: 341  token: 元\n",
            "char_count2: 342\n",
            "i: 342  token: 的\n",
            "char_count2: 343\n",
            "i: 343  token: 損\n",
            "char_count2: 344\n",
            "i: 344  token: 失\n",
            "char_count2: 345\n",
            "i: 345  token: ，\n",
            "char_count2: 346\n",
            "i: 346  token: 但\n",
            "char_count2: 347\n",
            "i: 347  token: 是\n",
            "char_count2: 348\n",
            "i: 348  token: 洩\n",
            "char_count2: 349\n",
            "i: 349  token: 洪\n",
            "char_count2: 350\n",
            "i: 350  token: 水\n",
            "char_count2: 351\n",
            "i: 351  token: 道\n",
            "char_count2: 352\n",
            "i: 352  token: 阻\n",
            "char_count2: 353\n",
            "i: 353  token: 止\n",
            "char_count2: 354\n",
            "i: 354  token: 了\n",
            "char_count2: 355\n",
            "i: 355  token: 洪\n",
            "char_count2: 356\n",
            "i: 356  token: 水\n",
            "char_count2: 357\n",
            "i: 357  token: 湧\n",
            "char_count2: 358\n",
            "i: 358  token: 入\n",
            "char_count2: 359\n",
            "i: 359  token: 溫\n",
            "char_count2: 360\n",
            "i: 360  token: 尼\n",
            "char_count2: 361\n",
            "i: 361  token: 伯\n",
            "char_count2: 362\n",
            "i: 362  token: 市\n",
            "char_count2: 363\n",
            "i: 363  token: 區\n",
            "char_count2: 364\n",
            "i: 364  token: 。\n",
            "char_count2: 365\n",
            "i: 365  token: 1990\n",
            "char_count2: 366\n",
            "i: 366  token: 年\n",
            "char_count2: 367\n",
            "i: 367  token: ，\n",
            "char_count2: 368\n",
            "i: 368  token: 時\n",
            "char_count2: 369\n",
            "i: 369  token: 任\n",
            "char_count2: 370\n",
            "i: 370  token: 總\n",
            "char_count2: 371\n",
            "i: 371  token: 理\n",
            "char_count2: 372\n",
            "i: 372  token: [UNK]\n",
            "new_start1: 372\n",
            "char_count1: 373\n",
            "i: 373  token: [UNK]\n",
            "new_start 372\n",
            "new_end 373\n",
            "final prediction 4億\n",
            "found [UNK] in prediction.\n",
            "original pred: 對 日 本 報 紙 的 無 恥 造 謠 誣 [UNK] ， 進 行 了 有 力 駁 斥\n",
            "start: 103\n",
            "end: 122\n",
            "i: 0  token: 梁\n",
            "char_count2: 1\n",
            "i: 1  token: 啟\n",
            "char_count2: 2\n",
            "i: 2  token: 超\n",
            "char_count2: 3\n",
            "i: 3  token: 對\n",
            "char_count2: 4\n",
            "i: 4  token: 日\n",
            "char_count2: 5\n",
            "i: 5  token: 本\n",
            "char_count2: 6\n",
            "i: 6  token: 痛\n",
            "char_count2: 7\n",
            "i: 7  token: 斥\n",
            "char_count2: 8\n",
            "i: 8  token: ，\n",
            "char_count2: 9\n",
            "i: 9  token: 使\n",
            "char_count2: 10\n",
            "i: 10  token: 其\n",
            "char_count2: 11\n",
            "i: 11  token: 大\n",
            "char_count2: 12\n",
            "i: 12  token: 為\n",
            "char_count2: 13\n",
            "i: 13  token: 恐\n",
            "char_count2: 14\n",
            "i: 14  token: 慌\n",
            "char_count2: 15\n",
            "i: 15  token: 。\n",
            "char_count2: 16\n",
            "i: 16  token: 起\n",
            "char_count2: 17\n",
            "i: 17  token: 初\n",
            "char_count2: 18\n",
            "i: 18  token: ，\n",
            "char_count2: 19\n",
            "i: 19  token: 日\n",
            "char_count2: 20\n",
            "i: 20  token: 本\n",
            "char_count2: 21\n",
            "i: 21  token: 人\n",
            "char_count2: 22\n",
            "i: 22  token: 絡\n",
            "char_count2: 23\n",
            "i: 23  token: 繹\n",
            "char_count2: 24\n",
            "i: 24  token: 不\n",
            "char_count2: 25\n",
            "i: 25  token: 絕\n",
            "char_count2: 26\n",
            "i: 26  token: 地\n",
            "char_count2: 27\n",
            "i: 27  token: 去\n",
            "char_count2: 28\n",
            "i: 28  token: 天\n",
            "char_count2: 29\n",
            "i: 29  token: 津\n",
            "char_count2: 30\n",
            "i: 30  token: 對\n",
            "char_count2: 31\n",
            "i: 31  token: 梁\n",
            "char_count2: 32\n",
            "i: 32  token: 進\n",
            "char_count2: 33\n",
            "i: 33  token: 行\n",
            "char_count2: 34\n",
            "i: 34  token: 收\n",
            "char_count2: 35\n",
            "i: 35  token: 買\n",
            "char_count2: 36\n",
            "i: 36  token: 。\n",
            "char_count2: 37\n",
            "i: 37  token: 梁\n",
            "char_count2: 38\n",
            "i: 38  token: 則\n",
            "char_count2: 39\n",
            "i: 39  token: 嚴\n",
            "char_count2: 40\n",
            "i: 40  token: 詞\n",
            "char_count2: 41\n",
            "i: 41  token: 拒\n",
            "char_count2: 42\n",
            "i: 42  token: 絕\n",
            "char_count2: 43\n",
            "i: 43  token: 。\n",
            "char_count2: 44\n",
            "i: 44  token: 後\n",
            "char_count2: 45\n",
            "i: 45  token: 來\n",
            "char_count2: 46\n",
            "i: 46  token: ，\n",
            "char_count2: 47\n",
            "i: 47  token: 日\n",
            "char_count2: 48\n",
            "i: 48  token: 本\n",
            "char_count2: 49\n",
            "i: 49  token: 報\n",
            "char_count2: 50\n",
            "i: 50  token: 紙\n",
            "char_count2: 51\n",
            "i: 51  token: 大\n",
            "char_count2: 52\n",
            "i: 52  token: 肆\n",
            "char_count2: 53\n",
            "i: 53  token: 造\n",
            "char_count2: 54\n",
            "i: 54  token: 謠\n",
            "char_count2: 55\n",
            "i: 55  token: ，\n",
            "char_count2: 56\n",
            "i: 56  token: 說\n",
            "char_count2: 57\n",
            "i: 57  token: 德\n",
            "char_count2: 58\n",
            "i: 58  token: 國\n",
            "char_count2: 59\n",
            "i: 59  token: 人\n",
            "char_count2: 60\n",
            "i: 60  token: 以\n",
            "char_count2: 61\n",
            "i: 61  token: 金\n",
            "char_count2: 62\n",
            "i: 62  token: 錢\n",
            "char_count2: 63\n",
            "i: 63  token: 運\n",
            "char_count2: 64\n",
            "i: 64  token: 動\n",
            "char_count2: 65\n",
            "i: 65  token: 梁\n",
            "char_count2: 66\n",
            "i: 66  token: 啟\n",
            "char_count2: 67\n",
            "i: 67  token: 超\n",
            "char_count2: 68\n",
            "i: 68  token: ，\n",
            "char_count2: 69\n",
            "i: 69  token: 故\n",
            "char_count2: 70\n",
            "i: 70  token: 梁\n",
            "char_count2: 71\n",
            "i: 71  token: 攻\n",
            "char_count2: 72\n",
            "i: 72  token: 擊\n",
            "char_count2: 73\n",
            "i: 73  token: 日\n",
            "char_count2: 74\n",
            "i: 74  token: 本\n",
            "char_count2: 75\n",
            "i: 75  token: 以\n",
            "char_count2: 76\n",
            "i: 76  token: 袒\n",
            "char_count2: 77\n",
            "i: 77  token: 護\n",
            "char_count2: 78\n",
            "i: 78  token: 德\n",
            "char_count2: 79\n",
            "i: 79  token: 國\n",
            "char_count2: 80\n",
            "i: 80  token: 。\n",
            "char_count2: 81\n",
            "i: 81  token: 梁\n",
            "char_count2: 82\n",
            "i: 82  token: 啟\n",
            "char_count2: 83\n",
            "i: 83  token: 超\n",
            "char_count2: 84\n",
            "i: 84  token: 為\n",
            "char_count2: 85\n",
            "i: 85  token: 此\n",
            "char_count2: 86\n",
            "i: 86  token: 專\n",
            "char_count2: 87\n",
            "i: 87  token: 門\n",
            "char_count2: 88\n",
            "i: 88  token: 寫\n",
            "char_count2: 89\n",
            "i: 89  token: 了\n",
            "char_count2: 90\n",
            "i: 90  token: 《\n",
            "char_count2: 91\n",
            "i: 91  token: 中\n",
            "char_count2: 92\n",
            "i: 92  token: 日\n",
            "char_count2: 93\n",
            "i: 93  token: 時\n",
            "char_count2: 94\n",
            "i: 94  token: 局\n",
            "char_count2: 95\n",
            "i: 95  token: 與\n",
            "char_count2: 96\n",
            "i: 96  token: 鄙\n",
            "char_count2: 97\n",
            "i: 97  token: 人\n",
            "char_count2: 98\n",
            "i: 98  token: 之\n",
            "char_count2: 99\n",
            "i: 99  token: 言\n",
            "char_count2: 100\n",
            "i: 100  token: 論\n",
            "char_count2: 101\n",
            "i: 101  token: 》\n",
            "char_count2: 102\n",
            "i: 102  token: ，\n",
            "char_count2: 103\n",
            "i: 103  token: 對\n",
            "new_start2: 103\n",
            "char_count2: 104\n",
            "i: 104  token: 日\n",
            "char_count2: 105\n",
            "i: 105  token: 本\n",
            "char_count2: 106\n",
            "i: 106  token: 報\n",
            "char_count2: 107\n",
            "i: 107  token: 紙\n",
            "char_count2: 108\n",
            "i: 108  token: 的\n",
            "char_count2: 109\n",
            "i: 109  token: 無\n",
            "char_count2: 110\n",
            "i: 110  token: 恥\n",
            "char_count2: 111\n",
            "i: 111  token: 造\n",
            "char_count2: 112\n",
            "i: 112  token: 謠\n",
            "char_count2: 113\n",
            "i: 113  token: 誣\n",
            "char_count2: 114\n",
            "i: 114  token: [UNK]\n",
            "char_count1: 115\n",
            "i: 115  token: ，\n",
            "char_count2: 116\n",
            "i: 116  token: 進\n",
            "char_count2: 117\n",
            "i: 117  token: 行\n",
            "char_count2: 118\n",
            "i: 118  token: 了\n",
            "char_count2: 119\n",
            "i: 119  token: 有\n",
            "char_count2: 120\n",
            "i: 120  token: 力\n",
            "char_count2: 121\n",
            "i: 121  token: 駁\n",
            "char_count2: 122\n",
            "i: 122  token: 斥\n",
            "new_start 103\n",
            "new_end 122\n",
            "final prediction 對日本報紙的無恥造謠誣衊，進行了有力駁斥\n",
            "found [UNK] in prediction.\n",
            "original pred: 杜 恆 - [UNK] 因 論 題\n",
            "start: 6\n",
            "end: 12\n",
            "i: 0  token: 事\n",
            "char_count2: 1\n",
            "i: 1  token: 實\n",
            "char_count2: 2\n",
            "i: 2  token: 上\n",
            "char_count2: 3\n",
            "i: 3  token: ，\n",
            "char_count2: 4\n",
            "i: 4  token: 根\n",
            "char_count2: 5\n",
            "i: 5  token: 據\n",
            "char_count2: 6\n",
            "i: 6  token: 杜\n",
            "new_start2: 6\n",
            "char_count2: 7\n",
            "i: 7  token: 恆\n",
            "char_count2: 8\n",
            "i: 8  token: -\n",
            "char_count2: 9\n",
            "i: 9  token: [UNK]\n",
            "char_count1: 10\n",
            "i: 10  token: 因\n",
            "char_count2: 11\n",
            "i: 11  token: 論\n",
            "char_count2: 12\n",
            "i: 12  token: 題\n",
            "new_start 6\n",
            "new_end 12\n",
            "final prediction 杜恆-蒯因論題\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 5\n",
        "validation = True\n",
        "logging_step = 100\n",
        "learning_rate = 1e-5\n",
        "doc_stride = 50\n",
        "# doc_stride = 150\n",
        "accum_iter = 4\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_training_steps = len(train_loader) * num_epoch\n",
        "\n",
        "scheudler = transformers.get_polynomial_decay_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps, lr_end = 1e-07, power = 1.0, last_epoch = -1)\n",
        "\n",
        "if fp16_training:\n",
        "    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader) \n",
        "\n",
        "model.train()\n",
        "\n",
        "print(\"Start Training ...\")\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    step = 1\n",
        "    train_loss = train_acc = 0\n",
        "    \n",
        "    for data in tqdm(train_loader):\t\n",
        "        # Load all data into GPU\n",
        "        data = [i.to(device) for i in data]\n",
        "        \n",
        "        # Model inputs: input_ids, token_type_ids, attention_mask, start_positions, end_positions (Note: only \"input_ids\" is mandatory)\n",
        "        # Model outputs: start_logits, end_logits, loss (return when start_positions/end_positions are provided)  \n",
        "        output = model(input_ids=data[0], token_type_ids=data[1], attention_mask=data[2], start_positions=data[3], end_positions=data[4])\n",
        "\n",
        "        # Choose the most probable start position / end position\n",
        "        start_index = torch.argmax(output.start_logits, dim=1)\n",
        "        end_index = torch.argmax(output.end_logits, dim=1)\n",
        "        \n",
        "        # Prediction is correct only if both start_index and end_index are correct\n",
        "        train_acc += ((start_index == data[3]) & (end_index == data[4])).float().mean()\n",
        "        train_loss += output.loss\n",
        "        # output.loss = output.loss / accum_iter\n",
        "        \n",
        "        if fp16_training:\n",
        "            accelerator.backward(output.loss)\n",
        "        else:\n",
        "            output.loss.backward()\n",
        "        \n",
        "        # if ((idx + 1) % accum_iter == 0) or (idx + 1 == len(train_loader)):\n",
        "        optimizer.step()\n",
        "        scheudler.step()\n",
        "        optimizer.zero_grad()\n",
        "        step += 1\n",
        "\n",
        "        ##### TODO: Apply linear learning rate decay #####\n",
        "        \n",
        "        \n",
        "        # Print training loss and accuracy over past logging step\n",
        "        if step % logging_step == 0:\n",
        "            print(f\"Epoch {epoch + 1} | Step {step} | loss = {train_loss.item() / logging_step:.3f}, acc = {train_acc / logging_step:.3f}\")\n",
        "            train_loss = train_acc = 0\n",
        "\n",
        "    if validation:\n",
        "        print(\"Evaluating Dev Set ...\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            dev_acc = 0\n",
        "            for i, data in enumerate(tqdm(dev_loader)):\n",
        "                output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n",
        "                       attention_mask=data[2].squeeze(dim=0).to(device))\n",
        "                # prediction is correct only if answer text exactly matches\n",
        "                dev_acc += evaluate(data, output, doc_stride, dev_paragraphs[dev_questions[i]['paragraph_id']], \n",
        "                    dev_paragraphs_tokenized[dev_questions[i]['paragraph_id']].tokens) == dev_questions[i][\"answer_text\"]\n",
        "            print(f\"Validation | Epoch {epoch + 1} | acc = {dev_acc / len(dev_loader):.3f}\")\n",
        "        model.train()\n",
        "\n",
        "# Save a model and its configuration file to the directory 「saved_model」 \n",
        "# i.e. there are two files under the direcory 「saved_model」: 「pytorch_model.bin」 and 「config.json」\n",
        "# Saved model can be re-loaded using 「model = BertForQuestionAnswering.from_pretrained(\"saved_model\")」\n",
        "print(\"Saving Model ...\")\n",
        "model_save_dir = \"saved_model\" \n",
        "model.save_pretrained(model_save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMmdLOKBMsdE"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U5scNKC9xz0C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Test Set ...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating Test Set ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(test_loader)):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating Test Set ...\")\n",
        "\n",
        "result = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(tqdm(test_loader)):\n",
        "        output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n",
        "                       attention_mask=data[2].squeeze(dim=0).to(device))\n",
        "        result.append(evaluate(data, output, doc_stride, test_paragraphs[test_questions[i]['paragraph_id']],\n",
        "                               test_paragraphs_tokenized[test_questions[i]['paragraph_id']].tokens))\n",
        "\n",
        "result_file = \"result.csv\"\n",
        "with open(result_file, 'w') as f:\t\n",
        "\t  f.write(\"ID,Answer\\n\")\n",
        "\t  for i, test_question in enumerate(test_questions):\n",
        "        # Replace commas in answers with empty strings (since csv is separated by comma)\n",
        "        # Answers in kaggle are processed in the same way\n",
        "\t\t    f.write(f\"{test_question['id']},{result[i].replace(',','')}\\n\")\n",
        "\n",
        "print(f\"Completed! Result is in {result_file}\")"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3810jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "metadata": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    },
    "orig_nbformat": 3
  },
  "nbformat": 4,
  "nbformat_minor": 0
}